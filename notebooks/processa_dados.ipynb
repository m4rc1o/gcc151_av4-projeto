{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "processa_dados.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSQZq2WOr7b4",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Este notebook destina-se à formatação dos dados  utilizados no modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uby9i2jE83c6",
        "colab_type": "text"
      },
      "source": [
        "## Obtendo os dados não processados e o vetor de palavras pré-treinado(implementação utilizando o glove com 100 dimensões) do google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7Mg8VwtHPCB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run this cell to mount your Google Drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcP3RAx7HQAG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cp \"drive/My Drive/Colab Notebooks/PLN/text_sumarizer/data/news-of-the-site-folhauol.zip\" \"news-of-the-site-folhauol.zip\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9cURTWF3kMA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cp \"drive/My Drive/Colab Notebooks/PLN/text_sumarizer/models/glove_s100.zip\" \"glove_s100.zip\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOVEAMLL3kXV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cp -r \"drive/My Drive/Colab Notebooks/PLN/nlputils\" \"nlputils\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3IQ-gzi3kwy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cp \"drive/My Drive/Colab Notebooks/PLN/text_sumarizer/requirements.txt\" \"requirements.txt\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umFexWhlLA9X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from zipfile import ZipFile\n",
        "with ZipFile(\"news-of-the-site-folhauol.zip\", 'r') as zip_obj:\n",
        "    zip_obj.extractall()\n",
        "with ZipFile(\"glove_s100.zip\", 'r') as zip_obj:\n",
        "    zip_obj.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxPibpsJJ9NT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mv articles.csv dataset_artigos_de_noticias.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoNSZIGBLi1U",
        "colab_type": "code",
        "outputId": "2cb55522-6629-4a13-d643-e2debe5122b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "!pip3 install unidecode"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 3.5MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-m8DGlPL0eB",
        "colab_type": "code",
        "outputId": "bf27f21b-6528-47b5-ba20-25e83d35f317",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('rslp')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('perluniprops')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package perluniprops to /root/nltk_data...\n",
            "[nltk_data]   Unzipping misc/perluniprops.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_G7TjLZ5KdY3",
        "colab_type": "text"
      },
      "source": [
        "# Implementação do oprocessamento dos dados de um corpus de treinamento e de word embeddings pré-treinados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGXLYu3YKdY5",
        "colab_type": "text"
      },
      "source": [
        "## Carregando o dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EV2Te8dKdY7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocIo0nuDKdY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "caminho_dataset = \"dataset_artigos_de_noticias.csv\"\n",
        "dataset_noticias = pd.read_csv(caminho_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRSc5UAXKdZB",
        "colab_type": "code",
        "outputId": "b2e0aa11-bd8b-422a-eb6f-65fe2f1dec44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "# Exibe as 5 primeiras linhas do dataset carregado\n",
        "dataset_noticias.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>date</th>\n",
              "      <th>category</th>\n",
              "      <th>subcategory</th>\n",
              "      <th>link</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Lula diz que está 'lascado', mas que ainda tem...</td>\n",
              "      <td>Com a possibilidade de uma condenação impedir ...</td>\n",
              "      <td>2017-09-10</td>\n",
              "      <td>poder</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://www1.folha.uol.com.br/poder/2017/10/192...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>'Decidi ser escrava das mulheres que sofrem', ...</td>\n",
              "      <td>Para Oumou Sangaré, cantora e ativista malines...</td>\n",
              "      <td>2017-09-10</td>\n",
              "      <td>ilustrada</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://www1.folha.uol.com.br/ilustrada/2017/10...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Três reportagens da Folha ganham Prêmio Petrob...</td>\n",
              "      <td>Três reportagens da Folha foram vencedoras do ...</td>\n",
              "      <td>2017-09-10</td>\n",
              "      <td>poder</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://www1.folha.uol.com.br/poder/2017/10/192...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Filme 'Star Wars: Os Últimos Jedi' ganha trail...</td>\n",
              "      <td>A Disney divulgou na noite desta segunda-feira...</td>\n",
              "      <td>2017-09-10</td>\n",
              "      <td>ilustrada</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://www1.folha.uol.com.br/ilustrada/2017/10...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CBSS inicia acordos com fintechs e quer 30% do...</td>\n",
              "      <td>O CBSS, banco da holding Elopar dos sócios Bra...</td>\n",
              "      <td>2017-09-10</td>\n",
              "      <td>mercado</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://www1.folha.uol.com.br/mercado/2017/10/1...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title  ...                                               link\n",
              "0  Lula diz que está 'lascado', mas que ainda tem...  ...  http://www1.folha.uol.com.br/poder/2017/10/192...\n",
              "1  'Decidi ser escrava das mulheres que sofrem', ...  ...  http://www1.folha.uol.com.br/ilustrada/2017/10...\n",
              "2  Três reportagens da Folha ganham Prêmio Petrob...  ...  http://www1.folha.uol.com.br/poder/2017/10/192...\n",
              "3  Filme 'Star Wars: Os Últimos Jedi' ganha trail...  ...  http://www1.folha.uol.com.br/ilustrada/2017/10...\n",
              "4  CBSS inicia acordos com fintechs e quer 30% do...  ...  http://www1.folha.uol.com.br/mercado/2017/10/1...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPDQvka_KdZG",
        "colab_type": "code",
        "outputId": "ca0494ec-aa37-4bdf-9739-0dac2943b220",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(dataset_noticias)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "167053"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nUcfAt-KdZK",
        "colab_type": "code",
        "outputId": "e2ffda47-f92c-4472-bffa-47618927067a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "print(\"Título 3:\\n\", dataset_noticias['title'][3], '\\n')\n",
        "print(\"Texto 3:\\n\", dataset_noticias['text'][3], '\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Título 3:\n",
            " Filme 'Star Wars: Os Últimos Jedi' ganha trailer definitivo; assista \n",
            "\n",
            "Texto 3:\n",
            " A Disney divulgou na noite desta segunda-feira (9) o novo trailer de \"Star Wars: Os Últimos Jedi\", oitavo episódio da saga.  O trailer era aguardado pelos fãs e se tornou um dos tópicos mais comentados no Twitter no horário de seu lançamento.  Assista ao trailer de 'Os Últimos Jedi'  Assista ao trailer de 'Os Últimos Jedi'  Em \"O Despertar da Força\" (2015), episódio mais recente, a personagem Rey (Daisy Ridley) descobre que tem a Força e procura por Luke Skywalker (Mark Hamill) para começar seu treinamento Jedi.  A história do novo episódio continua desse ponto, e cenas do trailer mostram a relação entre Rey e Skywalker.  Com direção de Rian Johnson, o filme será lançado em 14 de dezembro no Brasil. O nono episódio, ainda sem título, encerra a nova trilogia em 20 de dezembro de 2019.  O estúdio também divulgou novo poster do filme.  Poster \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Alg-MaiKdZS",
        "colab_type": "text"
      },
      "source": [
        "## Tokenizando por palavras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgmvxPjhKdZT",
        "colab_type": "text"
      },
      "source": [
        "Obtendo um dicionário com todas as palavras distintas e suas respectivas frequências de ocorrência no dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtXU8KXCKdZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nlputils.lexical import normalization as norm\n",
        "normalizer = norm.Normalizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Udb37U1zBxsV",
        "colab_type": "text"
      },
      "source": [
        "Definindo uma rotina para processar o texto(remoção de informações inúteis)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zbioSOMFE6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
        "nao_remover = ['não', 'muito', 'mais']\n",
        "STOPWORDS = [word for word in stopwords if word not in nao_remover]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6AJeM1KG8LJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize.moses import MosesDetokenizer\n",
        "detokenizer = MosesDetokenizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ji0KLgK71X2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "def limpar_texto(texto, remover_stopwords=False):\n",
        "    \n",
        "    # Converte o texto para lower case\n",
        "    texto = texto.lower()\n",
        "    \n",
        "    # Remove caracteres indesejados\n",
        "    texto = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', texto, flags=re.MULTILINE)\n",
        "    texto = re.sub(r'\\<a href', ' ', texto)\n",
        "    texto = re.sub(r'&amp;', '', texto) \n",
        "    texto = re.sub(r'[_\"\\%()|+&=*%!?:#$@\\[\\]/]', ' ', texto)\n",
        "    texto = re.sub(r'<br />', ' ', texto)\n",
        "    texto = re.sub(r'\\'', ' ', texto)\n",
        "    \n",
        "    # Opcionalmente, remove stop words\n",
        "    if remover_stopwords:\n",
        "        tokens = [t for t in normalizer.tokenize_words(texto)\n",
        "                    if t not in STOPWORDS]\n",
        "        texto = detokenizer.detokenize(tokens, return_str=True)\n",
        "        \n",
        "    return texto\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNZXVatQKdZX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LIMITE = len(dataset_noticias)\n",
        "titulos = []\n",
        "textos = []\n",
        "tokens_freqs = {} # As chaves serão as palavras e os valores serão as frequências de ocorrência\n",
        "for i in range(LIMITE):\n",
        "    titulo = limpar_texto(str(dataset_noticias['title'][i]))\n",
        "    texto = limpar_texto(str(dataset_noticias['text'][i]), remover_stopwords=True)\n",
        "    titulos.append(titulo)\n",
        "    textos.append(texto)\n",
        "    conteudo = f\"{titulo}\\n{texto}\"\n",
        "    tokens = normalizer.tokenize_words(conteudo)\n",
        "    for token in tokens:\n",
        "        if token in tokens_freqs:\n",
        "            tokens_freqs[token] += 1\n",
        "        else:\n",
        "            tokens_freqs[token] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkFDjRjVCMuv",
        "colab_type": "text"
      },
      "source": [
        "Stop words foram removidas dos textos porque elas não provem muita utilidade no treinamento do modelo mas foram mantidas nos títulos(sumários) para que eles soem mais como frases naturais."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnA8kUAPKdZa",
        "colab_type": "code",
        "outputId": "18a17487-2bf8-4391-90c4-e2f0735e9bdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(tokens_freqs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "490517"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9uUx_kNKdZe",
        "colab_type": "text"
      },
      "source": [
        "Ordenando os tokens por frequência de ocorrência"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsrpVpVJKdZf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import OrderedDict\n",
        "from operator import itemgetter    \n",
        "\n",
        "tokens_freqs = OrderedDict(sorted(tokens_freqs.items(), key = itemgetter(1), reverse = True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "vK71HPc6KdZi",
        "colab_type": "code",
        "outputId": "1cdf207e-14be-4ec8-8971-e380e5652552",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print([(t, tokens_freqs[t]) for t in list(tokens_freqs)[:10]])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(',', 5475607), ('.', 3343955), ('é', 617776), ('não', 616527), ('mais', 352199), ('ser', 171453), ('r', 148691), ('sobre', 147632), ('anos', 147300), ('disse', 138526)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-KZ1gHSKdZm",
        "colab_type": "text"
      },
      "source": [
        "## Convertendo os tokens para representações vetoriais"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reOtKNXnKdZn",
        "colab_type": "text"
      },
      "source": [
        "Carregando os vetores de palavras pré-treinados(será usado o GloVe)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwjPGEu-Ljsb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "# Dicionário para converter um token para vetor\n",
        "token2vetor = {}\n",
        "\n",
        "with open(\"glove_s100.txt\", encoding=\"utf-8\") as glove_file:\n",
        "    for linha in glove_file: # Obs.: lixo será lido para a primeira linha\n",
        "        valor = linha.split(' ')\n",
        "        token = valor[0]\n",
        "        vetor = np.asarray(valor[1:], dtype='float32')\n",
        "        token2vetor[token] = vetor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAr6sP8rM-8b",
        "colab_type": "code",
        "outputId": "91947fe1-8484-4639-d3a0-90190a3e2dcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "token2vetor['de']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.059871, -0.26613 , -1.288952, -2.352894,  0.414237,  0.621193,\n",
              "        1.073003, -0.548189, -0.643191,  0.966722,  0.869204, -0.212642,\n",
              "       -1.038974, -0.356746, -0.24672 ,  0.471099,  0.049724, -0.7552  ,\n",
              "        0.388665,  1.053411,  0.940066, -0.405713,  0.007156, -1.134779,\n",
              "       -0.433221, -0.819711, -0.012   ,  0.032739, -0.225575,  1.153522,\n",
              "        0.537173, -0.463806,  0.340472, -0.189793, -0.160288,  0.58365 ,\n",
              "       -0.102506,  0.068884, -0.926536,  0.952415,  1.375001,  0.169173,\n",
              "       -0.055722, -0.356511,  0.559938,  0.414697, -0.747112, -0.548186,\n",
              "        0.35731 ,  0.851211,  0.036744, -0.746908, -0.305474, -0.137128,\n",
              "       -1.137372, -0.514234, -0.272096, -0.622991, -0.762249, -0.625595,\n",
              "        0.084059,  0.09621 ,  0.301824, -0.5573  ,  0.537335,  0.512624,\n",
              "       -0.435838,  0.591526, -0.318885,  0.181027,  1.253085,  0.257935,\n",
              "        0.734342,  0.245906,  2.948706,  0.0695  ,  0.484509, -0.255296,\n",
              "        0.019143, -0.773821,  0.55352 , -1.709604, -0.021685, -0.254114,\n",
              "       -0.576114, -0.800558, -0.022144, -0.281899, -0.949025,  0.329332,\n",
              "       -0.388322,  1.054918, -0.412016,  0.565986,  0.697279, -0.073342,\n",
              "        0.275684,  0.049941,  2.603193,  0.559911], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Bxx_1RsKdZ4",
        "colab_type": "code",
        "outputId": "4d0f7d01-3ba8-4eb0-9014-a62915187632",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "[token for token in list(token2vetor)[:10]]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['929605', ',', 'de', '.', 'a', 'o', 'e', 'que', 'do', 'da']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3hEt_ucPis1",
        "colab_type": "code",
        "outputId": "f37e7a52-caf8-49c8-ba00-4c900354065b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Remove o lixo lido para a primeira linha\n",
        "del token2vetor['929605']\n",
        "\n",
        "# Confirmando a exclusão\n",
        "[token for token in list(token2vetor)[:10]]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[',', 'de', '.', 'a', 'o', 'e', 'que', 'do', 'da', 'em']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Qlu09v2KdZ_",
        "colab_type": "text"
      },
      "source": [
        "Calculando o número de tokens do dataset que não não estão presentes no vocabulário do modelo GloVe e que têm uma frequência de ocorrência significativa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "civTiCBr-BsT",
        "colab_type": "code",
        "outputId": "32055d41-9ada-46f0-f8b9-b974f0432fa4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "qtd_tokens_faltantes = 0\n",
        "freq_min = 20\n",
        "\n",
        "for token, freq in tokens_freqs.items():\n",
        "    if freq > freq_min:\n",
        "        if token.lower() not in token2vetor:\n",
        "            qtd_tokens_faltantes += 1\n",
        "\n",
        "percent_tok_falt = round(qtd_tokens_faltantes*100/len(tokens_freqs), 2)\n",
        "print(\"Tokens faltantes no modelo GloVe: \", qtd_tokens_faltantes)\n",
        "print(f\"Percentual de tokens faltantes: {percent_tok_falt}%\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokens faltantes no modelo GloVe:  4711\n",
            "Percentual de tokens faltantes: 0.96%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuvNqyapBPZr",
        "colab_type": "text"
      },
      "source": [
        "Foi usada um frequência mínima(freq_min) de ocorrência, para que tokens que não estejam presentes no modelo GloVe possam ser adicionados à word_embedding_matrix, mas eles precisam ocorrer o bastante nos textos, de forma que o modelo consiga entender seus significados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsENWuPDCAQc",
        "colab_type": "code",
        "outputId": "a95c56ff-9b9e-41d2-9bd5-fe7eb58d8b7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Limita o vocabulário que será usado a tokens que têm uma \n",
        "# ocorrênica mínima >= freq_min ou fazem parte do vocabulário\n",
        "# do modelo do glove\n",
        "\n",
        "# Dicionário para converter tokens para inteiros\n",
        "token2int = {}\n",
        "\n",
        "# Dicionário para converter inteiros para tokens\n",
        "int2token = {}\n",
        "\n",
        "valor = 0\n",
        "for token, freq in tokens_freqs.items():\n",
        "    if freq >= freq_min or token.lower() in token2vetor:\n",
        "        token2int[token] = valor\n",
        "        int2token[valor] = token\n",
        "        valor += 1\n",
        "\n",
        "# Tokens especiais que serão adicionados ao dicionário\n",
        "tokens_espec = [\"<UNK>\",\"<PAD>\",\"<EOS>\",\"<GO>\"]\n",
        "\n",
        "# Adiciona os tokens especiais ao vocabulário\n",
        "for token in tokens_espec:\n",
        "    valor = len(token2int) # Os códigos especias serão os maiores códigos\n",
        "    token2int[token] = valor\n",
        "    int2token[valor] = token\n",
        "\n",
        "percent_uso_tok = round(len(token2int)/len(tokens_freqs), 4)*100    \n",
        "    \n",
        "print(\"Total de palavras distintas:\", len(tokens_freqs))\n",
        "print(\"Quantidade de palavras que serão usadas:\", len(token2int))\n",
        "print(f\"Percentual de uso de tokens: {percent_uso_tok}%\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total de palavras distintas: 490517\n",
            "Quantidade de palavras que serão usadas: 269660\n",
            "Percentual de uso de tokens: 54.97%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RpBNLsDIzb0",
        "colab_type": "text"
      },
      "source": [
        "Construindo a matriz de tokens(embedding matrix)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9K5GwGwTIxm0",
        "colab_type": "code",
        "outputId": "084a84a8-e04b-486c-a47b-6b1371e0b307",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "dim_vetor = 100 # Esse valor precisa conferir com o do modelo Glove\n",
        "qtd_tokens = len(token2int)\n",
        "\n",
        "# Cria a matrix com valores padrões como zero\n",
        "matriz_de_tokens = np.zeros((qtd_tokens, dim_vetor), dtype=np.float32)\n",
        "\n",
        "for token, valor in token2int.items():\n",
        "    if token in token2vetor:\n",
        "        matriz_de_tokens[valor] = token2vetor[token]\n",
        "    else:\n",
        "        # Se o token não estiver no modelo GloVe, cria um vetor aleatório para ele\n",
        "        novo_vetor = np.array(np.random.uniform(-1.0, 1.0, dim_vetor))\n",
        "        token2vetor[token] = novo_vetor\n",
        "        matriz_de_tokens[valor] = novo_vetor\n",
        "        \n",
        "# Confere se o valor bate com len(token2int)\n",
        "print(len(matriz_de_tokens))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "269660\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgGhju-Ip_W0",
        "colab_type": "text"
      },
      "source": [
        "## Convertendo títulos e textos para inteiros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKvWCRzVp-P2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def converter_para_ints(dados_text, qtd_tokens, qtd_desc, eos=False):\n",
        "    \"\"\"\n",
        "    Converte cada token no texto para um inteiro. Se o token\n",
        "    não estiver em token2int, usa token2int('<UNK>')\n",
        "    \n",
        "    params: \n",
        "        dados_text:  uma lista de strings, o texto a ser convertido\n",
        "        eos: bool, define se deve-se acrescentar ou não o \n",
        "             valor especial token2int('EOS') no final de cada \n",
        "             sentença\n",
        "        qtd_tokens: int, uma quantidade de tokens anterior\n",
        "        qtd_desc: int, um quantidade de tokens desconhecidos anterior\n",
        "    return:\n",
        "        ints: uma lista de inteiros, que representa o texto convertido\n",
        "        qtd_tokens: int, a quantidade de tokens anterior mais os do texto\n",
        "        qtd_desc: int, a quantidade de torkens desconhecidos anterior mais os do texto\n",
        "    \"\"\"\n",
        "    ints = []\n",
        "    for elemento in dados_text:\n",
        "        ints_sent = []\n",
        "        tokens = normalizer.tokenize_words(str(elemento))\n",
        "        qtd_tokens += len(tokens)\n",
        "        for token in tokens:\n",
        "            if token.lower() in token2int:\n",
        "                ints_sent.append(token2int[token.lower()])\n",
        "            else:\n",
        "                ints_sent.append(token2int['<UNK>'])\n",
        "                qtd_desc += 1\n",
        "        if eos:\n",
        "            ints_sent.append(token2int['<EOS>'])\n",
        "        ints.append(ints_sent)\n",
        "\n",
        "    return ints, qtd_tokens, qtd_desc\n",
        "            \n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLKYA2fZx7cu",
        "colab_type": "code",
        "outputId": "0f245ddc-2555-4e22-ab7a-7b52cf0725f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Aplica converter_para_ints a titulos e textos\n",
        "qtd_tokens = 0\n",
        "qtd_desc = 0\n",
        "\n",
        "int_titulos, qtd_tokens, qtd_desc = converter_para_ints(titulos, qtd_tokens, qtd_desc)\n",
        "int_textos, qtd_tokens, qtd_desc = converter_para_ints(textos, qtd_tokens, qtd_desc, eos=True)\n",
        "\n",
        "percent_desc = round(qtd_desc*100/qtd_tokens, 2)\n",
        "\n",
        "print(\"Número total de tokens:\", qtd_tokens)\n",
        "print(\"Número de tokens desconhecidos:\", qtd_desc)\n",
        "print(f\"Percentual de tokens desconhecidos: {percent_desc}%\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Número total de tokens: 55873196\n",
            "Número de tokens desconhecidos: 416224\n",
            "Percentual de tokens desconhecidos: 0.74%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruRJti1mxi7B",
        "colab_type": "code",
        "outputId": "c81e6572-f6a2-47d0-e86b-1660631a95c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(len(int_titulos), len(int_textos))\n",
        "print(\"Representação textual:\", titulos[3])\n",
        "print(\"Representação inteira:\", int_titulos[3])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "167053 167053\n",
            "Representação textual: filme  star wars  os últimos jedi  ganha trailer definitivo; assista\n",
            "Representação inteira: [265, 4497, 6290, 2425, 236, 20884, 1783, 4849, 6014, 51, 4731]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewWxNQqdN6Ue",
        "colab_type": "text"
      },
      "source": [
        "Definindo um função que cria um dataframe de tamanhos de textos de uma lista de textos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gbnqNrQN3QA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cria_tamanhos(lista_textos):\n",
        "    tamanhos = []\n",
        "    for texto in lista_textos:\n",
        "        tamanhos.append(len(texto))\n",
        "    return pd.DataFrame(tamanhos, columns=['quantidades'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irWbwuGpOtkV",
        "colab_type": "text"
      },
      "source": [
        "Criando dataframes com os tamanhos dos títulos e dos textos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukDed2tQOssV",
        "colab_type": "code",
        "outputId": "e784bae8-b56f-41dc-cb1b-d1f64000df01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "tamanhos_titulos = cria_tamanhos(int_titulos)\n",
        "tamanhos_textos = cria_tamanhos(int_textos)\n",
        "\n",
        "print(\"Tamanho dos títulos:\")\n",
        "print(tamanhos_titulos.describe())\n",
        "print()\n",
        "print(\"Tamanhos dos textos:\")\n",
        "print(tamanhos_textos.describe())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tamanho dos títulos:\n",
            "         quantidades\n",
            "count  167053.000000\n",
            "mean       10.478190\n",
            "std         3.069847\n",
            "min         1.000000\n",
            "25%         9.000000\n",
            "50%        11.000000\n",
            "75%        12.000000\n",
            "max        27.000000\n",
            "\n",
            "Tamanhos dos textos:\n",
            "         quantidades\n",
            "count  167053.000000\n",
            "mean      324.985699\n",
            "std       233.082603\n",
            "min         1.000000\n",
            "25%       183.000000\n",
            "50%       287.000000\n",
            "75%       412.000000\n",
            "max      8732.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtRckgaETj4O",
        "colab_type": "text"
      },
      "source": [
        "Definindo uma rotina para contar a quantidade de tokens desconhecidos em uma representação inteira de um texto qualquer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13UASY8tTC_z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conta_desc(int_texto):\n",
        "    qtd_desc = 0\n",
        "    for valor in int_texto:\n",
        "        if valor == token2int[\"<UNK>\"]:\n",
        "            qtd_desc += 1\n",
        "    return qtd_desc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFRNWCT-MAOf",
        "colab_type": "text"
      },
      "source": [
        "Ordenando os títulos e textos por tamanho dos textos, do menor para o maior. Limitando o tamanho de títulos e textos baseado em valores min e max e removendo entradas que possuem muitos tokens desconhecidos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0o0CQYeMyb9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dicionário para auxiliar na ordenação\n",
        "# As chaves serão os tamanhos dos textos e os valores serão \n",
        "# tuplas da forma (int_titulo, int_texto)\n",
        "conteudo_ordenado = {}\n",
        "\n",
        "tam_min_texto = min(tamanhos_textos.quantidades)\n",
        "tam_max_texto = max(tamanhos_textos.quantidades)\n",
        "tam_min_titulo = min(tamanhos_titulos.quantidades)\n",
        "tam_max_titulo = max(tamanhos_titulos.quantidades)\n",
        "tam_min = 2\n",
        "limite_desc_texto = 5\n",
        "limite_desc_titulo = 1\n",
        "\n",
        "limite = len(int_titulos)\n",
        "for i in range(limite):\n",
        "    tam_texto = len(int_textos[i])\n",
        "    tam_titulo = len(int_titulos[i])\n",
        "    qtd_desc_tit = conta_desc(int_titulos[i])\n",
        "    qtd_desc_txt = conta_desc(int_textos[i])\n",
        "    if tam_texto >= tam_min and tam_titulo >= tam_min and \\\n",
        "            qtd_desc_tit <= limite_desc_titulo and \\\n",
        "                qtd_desc_txt <= limite_desc_texto:\n",
        "        conteudo_ordenado[len(int_textos[i])] = (int_titulos[i].copy(), int_textos[i].copy())\n",
        "\n",
        "# Ordenando com base no tamanho dos textos\n",
        "conteudo_ordenado = OrderedDict(sorted(conteudo_ordenado.items(), key = itemgetter(0)))\n",
        "\n",
        "titulos_ordenados = []\n",
        "textos_ordenados = []\n",
        "for tam_texto, tup_tit_text in conteudo_ordenado.items():\n",
        "    titulos_ordenados.append(tup_tit_text[0])\n",
        "    textos_ordenados.append(tup_tit_text[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvvjGReEejcF",
        "colab_type": "code",
        "outputId": "8f97f8fc-01b7-480f-b88a-6e23ee580252",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(len(titulos_ordenados), len(textos_ordenados))\n",
        "print(titulos_ordenados[0])\n",
        "print(textos_ordenados[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1422 1422\n",
            "[3484, 163, 27954, 30, 20, 167, 207, 475, 51, 455, 19334, 163, 11445]\n",
            "[8153, 269658]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGcNr_8SpJlL",
        "colab_type": "text"
      },
      "source": [
        "## Dados gerados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57kvmLO0qlAF",
        "colab_type": "text"
      },
      "source": [
        "Os dados processados acima, foram salvos usando o pickle e podem ser encotrados em: [dados do modelo](https://drive.google.com/drive/folders/1b2bh5rYxr-RzJ8t2OiL3Cw0XqRNqGpTQ?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Xe0VDBSq9Ts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}