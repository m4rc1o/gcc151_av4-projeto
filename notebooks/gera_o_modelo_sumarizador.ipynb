{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gera_o_modelo_sumarizador.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXVzAgRz3HOs",
        "colab_type": "text"
      },
      "source": [
        "# Este notebook destina-se à geração do modelo utilizando os dados processados conforme o notebook processa_dados\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UL7h4q4lo9sF",
        "colab_type": "text"
      },
      "source": [
        "## Gerando o modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NpoPUH_45rN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Montando o Google Drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RVmcTH640t-",
        "colab_type": "code",
        "outputId": "404b50dd-57c5-4b08-c2b4-e41d62421703",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Run this cell to mount your Google Drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9I5kJNu1RZf",
        "colab_type": "text"
      },
      "source": [
        "Carregando dados processados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-5pvpyFzdaq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def carregar_dados_pickle(path):\n",
        "    import pickle\n",
        "    with open(path, \"rb\") as infile:\n",
        "        return pickle.load(infile)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vJ1q4m20Hud",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token2int, int2token = carregar_dados_pickle(\"drive/My Drive/text_sumarizer/data/token2int_int2token.pickle\")\n",
        "token2vetor = carregar_dados_pickle(\"drive/My Drive/text_sumarizer/data/token2vetor.pickle\")\n",
        "int_titulos_ord, int_textos_ord = carregar_dados_pickle(\"drive/My Drive/text_sumarizer/data/int_titulos_textos_ord.pickle\")\n",
        "matriz_de_tokens = carregar_dados_pickle(\"drive/My Drive/text_sumarizer/data/matriz_de_tokens.pickle\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVYi6YrD1YTO",
        "colab_type": "text"
      },
      "source": [
        "Será usado o TensorFlow para geração do modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UmHfrtRq-at",
        "colab_type": "code",
        "outputId": "ee4f1d36-182a-44aa-fd72-30ddb4c0ab6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.layers.core import Dense\n",
        "from tensorflow.python.ops.rnn_cell_impl import _zero_state_tensors\n",
        "print('Versão do TensorFlow: {}'.format(tf.__version__))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Versão do TensorFlow: 1.14.0-rc1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYATokbRF9BF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMdygKM-rlVw",
        "colab_type": "code",
        "outputId": "df2f6e11-d951-474b-d922-d44534c91f4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "nome_disp = tf.test.gpu_device_name()\n",
        "if nome_disp != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('GPU encontrada em: {}'.format(nome_disp))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU encontrada em: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hri5IsKEpS0q",
        "colab_type": "text"
      },
      "source": [
        "Definindo uma função para criar placeholders para os dados de entrada do modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zABXAuOWpEHv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def entradas_do_modelo():\n",
        "    #Cria placeholders para os dados de entrada\n",
        "    \n",
        "    dados_de_entrada = tf.placeholder(tf.int32, [None, None], name='entrada')\n",
        "    alvos = tf.placeholder(tf.int32, [None, None], name='alvos')\n",
        "    ta = tf.placeholder(tf.float32, name='taxa_aprend')\n",
        "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
        "    tam_sumario = tf.placeholder(tf.int32, (None,), name='tam_sumario')\n",
        "    tam_max_sumario = tf.reduce_max(tam_sumario, name='tam_max_dec')\n",
        "    tam_texto = tf.placeholder(tf.int32, (None,), name='tam_texto')\n",
        "\n",
        "    return dados_de_entrada, alvos, ta, keep_prob, tam_sumario, tam_max_sumario, tam_texto"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0zDQWz_615G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def codificar_entrada(dados_de_destino, token2int, tam_batch):\n",
        "    \"\"\"\n",
        "    Remove o último id de token de cada batch e concatena\n",
        "    o <GO> ao início de cada batch    \n",
        "    \"\"\"\n",
        "    \n",
        "    final = tf.strided_slice(dados_de_destino, [0, 0], \n",
        "                             [tam_batch, -1], [1, 1])\n",
        "    entrada_dec = tf.concat([tf.fill([tam_batch, 1], \n",
        "                             token2int['<GO>']), final], 1)\n",
        "\n",
        "    return entrada_dec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVHNFSLb-cpI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " def camada_de_codificacao(tam_rnn, tam_sequencia, num_camadas, entradas_rnn, keep_prob):\n",
        "    \"\"\"\n",
        "    Cria a camada de codificação\n",
        "    \"\"\"\n",
        "\n",
        "    for camada in range(num_camadas):\n",
        "        with tf.variable_scope('codificador_{}'.format(camada)):\n",
        "            celula_fw = tf.contrib.rnn.LSTMCell(tam_rnn,\n",
        "                        initializer=tf.random_uniform_initializer(-0.1, 0.1, seed=2))\n",
        "            celula_fw = tf.contrib.rnn.DropoutWrapper(celula_fw, \n",
        "                        input_keep_prob = keep_prob)\n",
        "\n",
        "            celula_bw = tf.contrib.rnn.LSTMCell(tam_rnn,\n",
        "                        initializer=tf.random_uniform_initializer(-0.1, 0.1, seed=2))\n",
        "            celula_bw = tf.contrib.rnn.DropoutWrapper(celula_bw, \n",
        "                        input_keep_prob = keep_prob)\n",
        "\n",
        "            saida_cod, estado_de_cod = tf.nn.bidirectional_dynamic_rnn(celula_fw, \n",
        "                                        celula_bw, entradas_rnn, tam_sequencia, \n",
        "                                            dtype=tf.float32)\n",
        "\n",
        "    # Junta as entradas porque estamos usando uma RNN bidirecional\n",
        "    saida_cod = tf.concat(saida_cod,2)\n",
        "\n",
        "    return saida_cod, estado_de_cod"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gkwkmQcDXxE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def treina_camada_decod(vetor_entrada_dec, tam_sumario, celula_dec, estado_inicial,\n",
        "                            camada_saida, tam_vocab, tam_max_sumario):\n",
        "    \n",
        "        \"\"\"Cria os treinadores logits\"\"\"\n",
        "    \n",
        "        treinador_auxiliar = tf.contrib.seq2seq.TrainingHelper(inputs=vetor_entrada_dec,\n",
        "                            sequence_length=tam_sumario, time_major=False)\n",
        "\n",
        "        treinador_decodificador = tf.contrib.seq2seq.BasicDecoder(celula_dec,\n",
        "                            treinador_auxiliar, estado_inicial,camada_saida) \n",
        "\n",
        "        treinador_logits, _ , _ = tf.contrib.seq2seq.dynamic_decode(treinador_decodificador,\n",
        "                                    output_time_major=False, impute_finished=True,\n",
        "                                        maximum_iterations=tam_max_sumario)\n",
        "        return treinador_decodificador"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayW1yWiYFxvV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def camada_de_decod_inferencial(vetores, token_inicial, token_final, celula_decod, \n",
        "                                    estado_inicial, camada_de_saida, tam_max_sumario, batch_size):\n",
        "        \n",
        "        \"\"\"\n",
        "        Cria logits inferenciais\n",
        "        \"\"\"\n",
        "        \n",
        "        tokens_iniciais = tf.tile(tf.constant([token_inicial], dtype=tf.int32), \n",
        "                                  [batch_size], name='tokens_iniciais')\n",
        "        \n",
        "        aux_inferencial = tf.contrib.seq2seq.GreedyEmbeddingHelper(vetores,\n",
        "                            tokens_iniciais, token_final)\n",
        "                    \n",
        "        decod_inferencial = tf.contrib.seq2seq.BasicDecoder(celula_decod,\n",
        "                                aux_inferencial, estado_inicial, camada_de_saida)\n",
        "                    \n",
        "        logits_inferencial, _ , _ = tf.contrib.seq2seq.dynamic_decode(decod_inferencial,\n",
        "                                        output_time_major=False, impute_finished=True,\n",
        "                                            maximum_iterations=tam_max_sumario)\n",
        "        \n",
        "        return decod_inferencial"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ee0AeLEbLx9G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def camada_de_decodificacao(vetor_entrada_dec, vetores, saida_cod, estado_de_cod, tam_vocab,\n",
        "                tam_texto, tam_sumario, tam_max_sumario, tam_rnn, token2int, keep_prob, \n",
        "                    tam_batch, num_camadas):\n",
        "\n",
        "    \"\"\"\n",
        "    Cria a célula de decodificação e atenção para o treinamento e camadas \n",
        "    decodificadoras inferenciais\n",
        "    \"\"\"\n",
        "    \n",
        "    for camada in range(num_camadas):\n",
        "        with tf.variable_scope('decodificador_{}'.format(camada)):\n",
        "            lstm = tf.contrib.rnn.LSTMCell(tam_rnn,\n",
        "                    initializer=tf.random_uniform_initializer(-0.1, 0.1, seed=2))\n",
        "            celula_decod = tf.contrib.rnn.DropoutWrapper(lstm, input_keep_prob = keep_prob)\n",
        "\n",
        "    camada_de_saida = Dense(tam_vocab, kernel_initializer= \n",
        "                        tf.truncated_normal_initializer(mean = 0.0, stddev=0.1))\n",
        "\n",
        "    mecan_atencao = tf.contrib.seq2seq.BahdanauAttention(tam_rnn,\n",
        "                    saida_cod, tam_texto, normalize=False, name='BahdanauAttention')\n",
        "\n",
        "    celula_decod = tf.contrib.seq2seq.AttentionWrapper(celula_decod, mecan_atencao, tam_rnn)\n",
        "\n",
        "    #estado_inicial = tf.contrib.seq2seq.AttentionWrapperState(estado_de_cod[0],\n",
        "    #                   _zero_state_tensors(tam_rnn, batch_size, tf.float32)) \n",
        "\n",
        "    estado_inicial = celula_decod.zero_state(batch_size=batch_size, \n",
        "                        dtype=tf.float32).clone(cell_state=estado_de_cod[0])\n",
        "\n",
        "    with tf.variable_scope(\"decode\"):\n",
        "        treinador_decodificador = treina_camada_decod(vetor_entrada_dec, tam_sumario, \n",
        "                                celula_decod, estado_inicial, camada_de_saida, tam_vocab, tam_max_sumario)\n",
        "\n",
        "        treinador_logits,_ ,_ = tf.contrib.seq2seq.dynamic_decode(treinador_decodificador,\n",
        "                                    output_time_major=False, impute_finished=True,\n",
        "                                        maximum_iterations=tam_max_sumario)\n",
        "\n",
        "    with tf.variable_scope(\"decode\", reuse=True): inference_decoder= \\\n",
        "                    camada_de_decod_inferencial(vetores, token2int['<GO>'], \n",
        "                        token2int['<EOS>'], celula_decod, estado_inicial, \n",
        "                            camada_de_saida, tam_max_sumario,  tam_batch)\n",
        "\n",
        "\n",
        "    logits_inferencial,_ ,_ = tf.contrib.seq2seq.dynamic_decode(inference_decoder,\n",
        "                            output_time_major=False,\n",
        "                            impute_finished=True,\n",
        "                            maximum_iterations=tam_max_sumario)\n",
        "\n",
        "    return treinador_logits, logits_inferencial"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNLn94TQPK8F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def modelo_seq2seq(dados_de_entrada, dados_de_destino, keep_prob, tam_texto, tam_sumario, tam_max_sumario, \n",
        "                  tam_vocab, tam_rnn, num_camadas, token2int, tam_batch):\n",
        "    \"\"\"\n",
        "    Usa as funções anteriores para criar os logits de treinamento inferenciais\n",
        "    \"\"\"\n",
        "    \n",
        "    # Usa os vetores do modelo GloVe e os novos gerados aleatoriamente\n",
        "    vetores = matriz_de_tokens\n",
        "    \n",
        "    vetores_ent_codif = tf.nn.embedding_lookup(vetores, dados_de_entrada)\n",
        "    saida_cod, estado_de_cod = camada_de_codificacao(tam_rnn, tam_texto, num_camadas, vetores_ent_codif, keep_prob)\n",
        "    \n",
        "    saida_decod = codificar_entrada(dados_de_destino, token2int, tam_batch)\n",
        "    vetor_entrada_dec = tf.nn.embedding_lookup(vetores, saida_decod)\n",
        "    \n",
        "    treinador_logits, logits_inferencial  = camada_de_decodificacao(vetor_entrada_dec, \n",
        "                                             vetores, saida_cod, estado_de_cod, \n",
        "                                                tam_vocab, tam_texto, tam_sumario, \n",
        "                                                    tam_max_sumario, tam_rnn, token2int, \n",
        "                                                        keep_prob, tam_batch, num_camadas)\n",
        "    \n",
        "    return treinador_logits, logits_inferencial"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NqGG9syQycj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preenche_grupo_de_sentencas(grupo_sents):\n",
        "    \"\"\"\n",
        "    Preenche as sentenças com <PAD> para que cada sentença de \n",
        "    um grupo de sentenças tenha o mesmo tamanho\n",
        "    \"\"\"\n",
        "\n",
        "    tam_max_sentenca = max([len(sentenca) for sentenca in grupo_sents])\n",
        "    return [sentenca + [token2int['<PAD>']] * (tam_max_sentenca - \\\n",
        "                len(sentenca)) for sentenca in grupo_sents]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sn9Bud7TUxyM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_batches(sumarios, textos, batch_size):\n",
        "    \"\"\"\n",
        "    Agrupa sumarios, textos, e os tamanhos de suas sentenças\n",
        "    \"\"\"\n",
        "    \n",
        "    for grupo_i in range(0, len(textos)//batch_size):\n",
        "        inicio_i = grupo_i * batch_size\n",
        "        grupo_de_sumarios = sumarios[inicio_i:inicio_i + batch_size]\n",
        "        grupo_de_textos = textos[inicio_i:inicio_i + batch_size]\n",
        "        preenche_grupo_de_sumarios = np.array(preenche_grupo_de_sentencas(grupo_de_sumarios))\n",
        "        preench_grupo_textos = np.array(preenche_grupo_de_sentencas(grupo_de_textos))\n",
        "        \n",
        "        # Need the lengths for the _lengths parameters\n",
        "        tams_preench_sums = []\n",
        "        for sumario in preenche_grupo_de_sumarios:\n",
        "            tams_preench_sums.append(len(sumario))\n",
        "        \n",
        "        tams_preench_textos = []\n",
        "        for text in preench_grupo_textos:\n",
        "            tams_preench_textos.append(len(text))\n",
        "        \n",
        "        yield preenche_grupo_de_sumarios, preench_grupo_textos, tams_preench_sums, tams_preench_textos"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJVptQVTXZrd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Seta os Hyperparametros\n",
        "epochs = 100\n",
        "batch_size = 64\n",
        "tam_rnn = 256\n",
        "num_camadas = 2\n",
        "taxa_aprend = 0.005\n",
        "keep_probab = 0.75"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhWLydzFb4fr",
        "colab_type": "code",
        "outputId": "bc4b3a61-2077-4525-ac61-5be99e9adf96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "# Constrói o Grafo\n",
        "grafo_de_treino = tf.Graph()\n",
        "# Seta o Grafo para o padrão para garantir que ele está pronto\n",
        "with grafo_de_treino.as_default():\n",
        "    \n",
        "    # Carrega as entradas do modelo    \n",
        "    dados_de_entrada, alvos, ta, keep_prob, tam_sumario, tam_max_sumario, tam_texto = entradas_do_modelo()\n",
        "\n",
        "    # Cria os treinadores logits e inferencial\n",
        "    treinador_logits, logits_inferencial = modelo_seq2seq(tf.reverse(dados_de_entrada, [-1]),\n",
        "                                            alvos, keep_prob, tam_texto, tam_sumario,\n",
        "                                                tam_max_sumario, len(token2int)+1, tam_rnn, \n",
        "                                                    num_camadas, token2int, batch_size)\n",
        "\n",
        "    # Cria os tensores para os treinadores logits e logits inferenciais\n",
        "    treinador_logits = tf.identity(treinador_logits.rnn_output, 'logits')\n",
        "    logits_inferencial = tf.identity(logits_inferencial.sample_id, name='predicoes')\n",
        "\n",
        "    # Cria os pesos para o \"sequence_loss\"\n",
        "    mascaras = tf.sequence_mask(tam_sumario, tam_max_sumario, dtype=tf.float32, name='mascaras')\n",
        "\n",
        "    with tf.name_scope(\"otimizacao\"):\n",
        "        # Função \"Loss\"\n",
        "        custo = tf.contrib.seq2seq.sequence_loss(\n",
        "            treinador_logits,\n",
        "            alvos,\n",
        "            mascaras)\n",
        "\n",
        "        # Otimizador\n",
        "        otimizador = tf.train.AdamOptimizer(taxa_aprend)\n",
        "\n",
        "        # Limitação do gradiente\n",
        "        gradientes = otimizador.compute_gradients(custo)\n",
        "        gradientes_limitados = [(tf.clip_by_value(grad, -5., 5.), var) for grad, var in gradientes if grad is not None]\n",
        "        train_op = otimizador.apply_gradients(gradientes_limitados)\n",
        "\n",
        "print(\"O Grafo foi construido.\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0624 20:12:39.630298 140345706928000 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "W0624 20:12:39.632451 140345706928000 deprecation.py:323] From <ipython-input-8-384285c4ae8e>:9: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "W0624 20:12:39.646617 140345706928000 deprecation.py:323] From <ipython-input-8-384285c4ae8e>:20: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
            "W0624 20:12:39.648264 140345706928000 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "W0624 20:12:39.824740 140345706928000 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:961: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0624 20:12:40.480171 140345706928000 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py:244: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0624 20:12:42.143778 140345706928000 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "O Grafo foi construido.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YY_u0J-MclUP",
        "colab_type": "text"
      },
      "source": [
        "# Treinando o Modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnZhaUX9cqRN",
        "colab_type": "text"
      },
      "source": [
        "Definindo um subconjunto do dataset para facilitar treinamentos de teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FEPxnVlcoFu",
        "colab_type": "code",
        "outputId": "f99094a3-4361-4071-d45a-fdfe7f1ce7c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "# Subconjunto de dados de treinamento\n",
        "inicio = 3000\n",
        "fim = inicio + 50000\n",
        "porcao_sumarios_ord = int_titulos_ord[inicio:fim]\n",
        "porcao_textos_ord = int_textos_ord[inicio:fim]\n",
        "print(\"Tamanho do menor texto na porção:\", len(porcao_textos_ord[0]))\n",
        "print(\"Tamanho do maior texto na porção:\", len(porcao_textos_ord[-1]))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-cd8b541cf4aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minicio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minicio\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mporcao_sumarios_ord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint_titulos_ord\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minicio\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mporcao_textos_ord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint_textos_ord\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minicio\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tamanho do menor texto na porção:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mporcao_textos_ord\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'int_titulos_ord' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtqYNUkhuU6s",
        "colab_type": "code",
        "outputId": "ad5e3c36-d7a3-485c-d3fd-8fb6e3bfd58a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# Treina o modelo\n",
        "decaimento_taxa_aprend = 0.95\n",
        "taxa_aprend_min = 0.0005\n",
        "mostrar_intervalo = 20 # Verifica \"training loss\" a cada 20 \"batches\"\n",
        "parar_antes = 0 \n",
        "parar = 6 #3 # Se o loss não diminuir em 3 verificações, pare o treinamento\n",
        "por_epoch = 3 # Faça 3 verificações de atualização por epoch\n",
        "verific_atualizacao = (len(porcao_textos_ord)//batch_size//por_epoch)-1\n",
        "\n",
        "atualiz_loss = 0 \n",
        "batch_loss = 0\n",
        "atualiz_loss_sumario = [] # Armazendo as atulizacões dos losses para salvar melhoras no modelo\n",
        "\n",
        "  \n",
        "tf.reset_default_graph()\n",
        "checkpoint = \"drive/My Drive/text_sumarizer/models/sum/best_model.ckpt\"\n",
        "with tf.Session(graph=grafo_de_treino) as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    \n",
        "    # Se quisermos continuar treinando uma sessão anterior\n",
        "    # loader = tf.train.import_meta_graph(checkpoint + '.meta')\n",
        "    # loader.restore(sess, checkpoint)\n",
        "    # sess.run(tf.local_variables_initializer())\n",
        "\n",
        "    for epoch_i in range(1, epochs+1):\n",
        "        atualiz_loss = 0\n",
        "        batch_loss = 0\n",
        "        for batch_i, (batch_sumarios, batch_textos, tams_sumarios, tams_textos) in enumerate(\n",
        "                get_batches(porcao_sumarios_ord, porcao_textos_ord, batch_size)):\n",
        "            tempo_inicio = time.time()\n",
        "            _, loss = sess.run(\n",
        "                [train_op, custo],\n",
        "                {dados_de_entrada: batch_textos,\n",
        "                 alvos: batch_sumarios,\n",
        "                 ta: taxa_aprend,\n",
        "                 tam_sumario: tams_sumarios,\n",
        "                 tam_texto: tams_textos,\n",
        "                 keep_prob: keep_probab})\n",
        "\n",
        "            batch_loss += loss\n",
        "            atualiz_loss += loss\n",
        "            tempo_fin = time.time()\n",
        "            tempo_batch = tempo_fin - tempo_inicio\n",
        "\n",
        "            if batch_i % mostrar_intervalo == 0 and batch_i > 0:\n",
        "                print('Epoch {:>3}/{} Batch {:>4}/{} - Loss: {:>6.3f}, Seconds: {:>4.2f}'\n",
        "                      .format(epoch_i,\n",
        "                              epochs, \n",
        "                              batch_i, \n",
        "                              len(porcao_textos_ord) // batch_size, \n",
        "                              batch_loss / mostrar_intervalo, \n",
        "                              tempo_batch*mostrar_intervalo))\n",
        "                batch_loss = 0\n",
        "                \n",
        "                #saver = tf.train.Saver() \n",
        "                #saver.save(sess, checkpoint)\n",
        "                \n",
        "            if batch_i % verific_atualizacao == 0 and batch_i > 0:\n",
        "                print(\"Perda média dessa atualização:\", round(atualiz_loss/verific_atualizacao,3))\n",
        "                atualiz_loss_sumario.append(atualiz_loss)\n",
        "                \n",
        "              \n",
        "                  \n",
        "                # Se a perda da atualização estiver em um novo mínimo, salve o modelo\n",
        "                if atualiz_loss <= min(atualiz_loss_sumario):\n",
        "                    print('Novo recorde!') \n",
        "                    parar_antes = 0\n",
        "                    saver = tf.train.Saver() \n",
        "                    saver.save(sess, checkpoint)\n",
        "\n",
        "                else:\n",
        "                    print(\"Sem melhora.\")\n",
        "                    parar_antes += 1\n",
        "                    if parar_antes == parar:\n",
        "                        break\n",
        "                atualiz_loss = 0\n",
        "            \n",
        "                    \n",
        "        # Reduz a taxa de aprendizado, mas não abaixo do seu valor mínimo\n",
        "        taxa_aprend *= decaimento_taxa_aprend\n",
        "        if taxa_aprend < taxa_aprend_min:\n",
        "            taxa_aprend = taxa_aprend_min\n",
        "        \n",
        "        if parar_antes == parar:\n",
        "            print(\"Parando o treinamento.\")\n",
        "            break\n",
        "\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Perda média dessa atualização: 20.175\n",
            "Novo recorde!\n",
            "Perda média dessa atualização: 21.496\n",
            "Sem melhora.\n",
            "Perda média dessa atualização: 7.531\n",
            "Novo recorde!\n",
            "Perda média dessa atualização: 10.228\n",
            "Sem melhora.\n",
            "Perda média dessa atualização: 8.367\n",
            "Sem melhora.\n",
            "Perda média dessa atualização: 6.727\n",
            "Novo recorde!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaLzSrXPNEas",
        "colab_type": "code",
        "outputId": "a49fe679-739a-4436-ee19-c2fec904bee0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "checkpoint = \"drive/My Drive/text_sumarizer/models/sum/best_model.ckpt\" \n",
        "\n",
        "grafo_carregado = tf.Graph()\n",
        "with tf.Session(graph=grafo_carregado) as sess:\n",
        "    # Carrega o modelo salvo\n",
        "    loader = tf.train.import_meta_graph(checkpoint + '.meta')\n",
        "    loader.restore(sess, checkpoint)\n",
        "    names = []\n",
        "    [names.append(n.name) for n in grafo_carregado.as_graph_def().node]\n",
        "names"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0624 20:09:13.655901 139855912085376 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['entrada',\n",
              " 'alvos',\n",
              " 'taxa_aprend',\n",
              " 'keep_prob',\n",
              " 'tam_sumario',\n",
              " 'Const',\n",
              " 'tam_max_dec',\n",
              " 'tam_texto',\n",
              " 'ReverseV2/axis',\n",
              " 'ReverseV2',\n",
              " 'embedding_lookup/params_0',\n",
              " 'embedding_lookup/axis',\n",
              " 'embedding_lookup',\n",
              " 'embedding_lookup/Identity',\n",
              " 'codificador_0/DropoutWrapperInit/Const',\n",
              " 'codificador_0/DropoutWrapperInit/Const_1',\n",
              " 'codificador_0/DropoutWrapperInit_1/Const',\n",
              " 'codificador_0/DropoutWrapperInit_1/Const_1',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/Rank',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/range/start',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/range/delta',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/range',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/concat/values_0',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/concat/axis',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/concat',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/transpose',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/sequence_length',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/Shape',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/strided_slice/stack',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/strided_slice/stack_1',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/strided_slice/stack_2',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/strided_slice',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims/dim',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/Const',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/concat/axis',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/concat',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/zeros/Const',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/zeros',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_1/dim',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_1',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/Const_1',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_2/dim',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_2',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/Const_2',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/concat_1/axis',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/concat_1',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/zeros_1/Const',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/zeros_1',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_3/dim',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_3',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/Const_3',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/Shape_1',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/stack',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/Equal',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/Const',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/All',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/Assert/Const',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/Assert/Const_1',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/Assert/Assert/data_0',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/Assert/Assert/data_2',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/Assert/Assert',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/CheckSeqLen',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/Shape_2',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/strided_slice_1/stack',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/strided_slice_1/stack_1',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/strided_slice_1/stack_2',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/strided_slice_1',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/Shape_3',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/strided_slice_2/stack',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/strided_slice_2/stack_1',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/strided_slice_2/stack_2',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/strided_slice_2',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/ExpandDims/dim',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/ExpandDims',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/Const_1',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/concat_1/axis',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/concat_1',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/zeros/Const',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/zeros',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/Const_2',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/Min',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/Const_3',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/Max',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/time',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/TensorArray',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/TensorArray_1',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/TensorArrayUnstack/Shape',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice/stack',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice/stack_1',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice/stack_2',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/TensorArrayUnstack/range/start',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/TensorArrayUnstack/range/delta',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/TensorArrayUnstack/range',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/Maximum/x',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/Maximum',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/Minimum',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/iteration_counter',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/Enter',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/Enter_1',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/Enter_2',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/Enter_3',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/Enter_4',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/Merge',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/Merge_1',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/Merge_2',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/Merge_3',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/Merge_4',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/Less/Enter',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/Less',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/Less_1/Enter',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/Less_1',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/LogicalAnd',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/LoopCond',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/Switch',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/Switch_1',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/Switch_2',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/Switch_3',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/Switch_4',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/Identity',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/Identity_1',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/Identity_2',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/Identity_3',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/Identity_4',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/add/y',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/add',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/TensorArrayReadV3',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/GreaterEqual/Enter',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/GreaterEqual',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/sub/x',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/sub/Enter',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/sub',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/dropout/Shape',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/dropout/random_uniform/min',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/dropout/random_uniform/max',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/dropout/random_uniform/RandomUniform',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/dropout/random_uniform/sub',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/dropout/random_uniform/mul',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/dropout/random_uniform',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/dropout/sub/x',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/dropout/sub',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/dropout/truediv/x',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/dropout/truediv',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/dropout/GreaterEqual',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/dropout/mul',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/dropout/Cast',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/dropout/mul_1',\n",
              " 'codificador_0/bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/shape',\n",
              " 'codificador_0/bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/min',\n",
              " 'codificador_0/bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/max',\n",
              " 'codificador_0/bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/RandomUniform',\n",
              " 'codificador_0/bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/sub',\n",
              " 'codificador_0/bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/mul',\n",
              " 'codificador_0/bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform',\n",
              " 'codificador_0/bidirectional_rnn/fw/lstm_cell/kernel',\n",
              " 'codificador_0/bidirectional_rnn/fw/lstm_cell/kernel/Assign',\n",
              " 'codificador_0/bidirectional_rnn/fw/lstm_cell/kernel/read',\n",
              " 'codificador_0/bidirectional_rnn/fw/lstm_cell/bias/Initializer/zeros/shape_as_tensor',\n",
              " 'codificador_0/bidirectional_rnn/fw/lstm_cell/bias/Initializer/zeros/Const',\n",
              " 'codificador_0/bidirectional_rnn/fw/lstm_cell/bias/Initializer/zeros',\n",
              " 'codificador_0/bidirectional_rnn/fw/lstm_cell/bias',\n",
              " 'codificador_0/bidirectional_rnn/fw/lstm_cell/bias/Assign',\n",
              " 'codificador_0/bidirectional_rnn/fw/lstm_cell/bias/read',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/lstm_cell/concat/axis',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/lstm_cell/concat',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/lstm_cell/MatMul/Enter',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/lstm_cell/MatMul',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/lstm_cell/BiasAdd/Enter',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/lstm_cell/BiasAdd',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/lstm_cell/Const',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/lstm_cell/split/split_dim',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/lstm_cell/split',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/lstm_cell/add/y',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/lstm_cell/add',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/lstm_cell/Sigmoid',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/lstm_cell/mul',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/lstm_cell/Sigmoid_1',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/lstm_cell/Tanh',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/lstm_cell/mul_1',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/lstm_cell/add_1',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/lstm_cell/Sigmoid_2',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/lstm_cell/Tanh_1',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/lstm_cell/mul_2',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/Select/Enter',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/Select',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/Select_1',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/Select_2',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3/Enter',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/add_1/y',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/add_1',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/NextIteration',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/NextIteration_1',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/NextIteration_2',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/NextIteration_3',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/NextIteration_4',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/Exit',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/Exit_1',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/Exit_2',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/Exit_3',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/while/Exit_4',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/TensorArrayStack/TensorArraySizeV3',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/TensorArrayStack/range/start',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/TensorArrayStack/range/delta',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/TensorArrayStack/range',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/TensorArrayStack/TensorArrayGatherV3',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/Const_4',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/Rank_1',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/range_1/start',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/range_1/delta',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/range_1',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/concat_2/values_0',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/concat_2/axis',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/concat_2',\n",
              " 'codificador_0/bidirectional_rnn/fw/fw/transpose_1',\n",
              " 'codificador_0/bidirectional_rnn/bw/ReverseSequence',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/Rank',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/range/start',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/range/delta',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/range',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/concat/values_0',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/concat/axis',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/concat',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/transpose',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/sequence_length',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/Shape',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/strided_slice/stack',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/strided_slice/stack_1',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/strided_slice/stack_2',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/strided_slice',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims/dim',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/Const',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/concat/axis',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/concat',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/zeros/Const',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/zeros',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_1/dim',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_1',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/Const_1',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_2/dim',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_2',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/Const_2',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/concat_1/axis',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/concat_1',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/zeros_1/Const',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/zeros_1',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_3/dim',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_3',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/Const_3',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/Shape_1',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/stack',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/Equal',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/Const',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/All',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/Assert/Const',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/Assert/Const_1',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/Assert/Assert/data_0',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/Assert/Assert/data_2',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/Assert/Assert',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/CheckSeqLen',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/Shape_2',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/strided_slice_1/stack',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/strided_slice_1/stack_1',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/strided_slice_1/stack_2',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/strided_slice_1',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/Shape_3',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/strided_slice_2/stack',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/strided_slice_2/stack_1',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/strided_slice_2/stack_2',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/strided_slice_2',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/ExpandDims/dim',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/ExpandDims',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/Const_1',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/concat_1/axis',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/concat_1',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/zeros/Const',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/zeros',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/Const_2',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/Min',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/Const_3',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/Max',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/time',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/TensorArray',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/TensorArray_1',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/TensorArrayUnstack/Shape',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice/stack',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice/stack_1',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice/stack_2',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/TensorArrayUnstack/range/start',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/TensorArrayUnstack/range/delta',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/TensorArrayUnstack/range',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/Maximum/x',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/Maximum',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/Minimum',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/iteration_counter',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/Enter',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/Enter_1',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/Enter_2',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/Enter_3',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/Enter_4',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/Merge',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/Merge_1',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/Merge_2',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/Merge_3',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/Merge_4',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/Less/Enter',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/Less',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/Less_1/Enter',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/Less_1',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/LogicalAnd',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/LoopCond',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/Switch',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/Switch_1',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/Switch_2',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/Switch_3',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/Switch_4',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/Identity',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/Identity_1',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/Identity_2',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/Identity_3',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/Identity_4',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/add/y',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/add',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/TensorArrayReadV3',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/GreaterEqual/Enter',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/GreaterEqual',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/sub/x',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/sub/Enter',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/sub',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/dropout/Shape',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/dropout/random_uniform/min',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/dropout/random_uniform/max',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/dropout/random_uniform/RandomUniform',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/dropout/random_uniform/sub',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/dropout/random_uniform/mul',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/dropout/random_uniform',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/dropout/sub/x',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/dropout/sub',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/dropout/truediv/x',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/dropout/truediv',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/dropout/GreaterEqual',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/dropout/mul',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/dropout/Cast',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/dropout/mul_1',\n",
              " 'codificador_0/bidirectional_rnn/bw/lstm_cell/kernel/Initializer/random_uniform/shape',\n",
              " 'codificador_0/bidirectional_rnn/bw/lstm_cell/kernel/Initializer/random_uniform/min',\n",
              " 'codificador_0/bidirectional_rnn/bw/lstm_cell/kernel/Initializer/random_uniform/max',\n",
              " 'codificador_0/bidirectional_rnn/bw/lstm_cell/kernel/Initializer/random_uniform/RandomUniform',\n",
              " 'codificador_0/bidirectional_rnn/bw/lstm_cell/kernel/Initializer/random_uniform/sub',\n",
              " 'codificador_0/bidirectional_rnn/bw/lstm_cell/kernel/Initializer/random_uniform/mul',\n",
              " 'codificador_0/bidirectional_rnn/bw/lstm_cell/kernel/Initializer/random_uniform',\n",
              " 'codificador_0/bidirectional_rnn/bw/lstm_cell/kernel',\n",
              " 'codificador_0/bidirectional_rnn/bw/lstm_cell/kernel/Assign',\n",
              " 'codificador_0/bidirectional_rnn/bw/lstm_cell/kernel/read',\n",
              " 'codificador_0/bidirectional_rnn/bw/lstm_cell/bias/Initializer/zeros/shape_as_tensor',\n",
              " 'codificador_0/bidirectional_rnn/bw/lstm_cell/bias/Initializer/zeros/Const',\n",
              " 'codificador_0/bidirectional_rnn/bw/lstm_cell/bias/Initializer/zeros',\n",
              " 'codificador_0/bidirectional_rnn/bw/lstm_cell/bias',\n",
              " 'codificador_0/bidirectional_rnn/bw/lstm_cell/bias/Assign',\n",
              " 'codificador_0/bidirectional_rnn/bw/lstm_cell/bias/read',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/lstm_cell/concat/axis',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/lstm_cell/concat',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/lstm_cell/MatMul/Enter',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/lstm_cell/MatMul',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/lstm_cell/BiasAdd/Enter',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/lstm_cell/BiasAdd',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/lstm_cell/Const',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/lstm_cell/split/split_dim',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/lstm_cell/split',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/lstm_cell/add/y',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/lstm_cell/add',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/lstm_cell/Sigmoid',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/lstm_cell/mul',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/lstm_cell/Sigmoid_1',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/lstm_cell/Tanh',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/lstm_cell/mul_1',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/lstm_cell/add_1',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/lstm_cell/Sigmoid_2',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/lstm_cell/Tanh_1',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/lstm_cell/mul_2',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/Select/Enter',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/Select',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/Select_1',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/Select_2',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3/Enter',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/add_1/y',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/add_1',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/NextIteration',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/NextIteration_1',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/NextIteration_2',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/NextIteration_3',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/NextIteration_4',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/Exit',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/Exit_1',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/Exit_2',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/Exit_3',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/while/Exit_4',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/TensorArrayStack/TensorArraySizeV3',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/TensorArrayStack/range/start',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/TensorArrayStack/range/delta',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/TensorArrayStack/range',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/TensorArrayStack/TensorArrayGatherV3',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/Const_4',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/Rank_1',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/range_1/start',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/range_1/delta',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/range_1',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/concat_2/values_0',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/concat_2/axis',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/concat_2',\n",
              " 'codificador_0/bidirectional_rnn/bw/bw/transpose_1',\n",
              " 'codificador_0/ReverseSequence',\n",
              " 'codificador_1/DropoutWrapperInit/Const',\n",
              " 'codificador_1/DropoutWrapperInit/Const_1',\n",
              " 'codificador_1/DropoutWrapperInit_1/Const',\n",
              " 'codificador_1/DropoutWrapperInit_1/Const_1',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/Rank',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/range/start',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/range/delta',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/range',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/concat/values_0',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/concat/axis',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/concat',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/transpose',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/sequence_length',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/Shape',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/strided_slice/stack',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/strided_slice/stack_1',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/strided_slice/stack_2',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/strided_slice',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims/dim',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/Const',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/concat/axis',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/concat',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/zeros/Const',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/zeros',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_1/dim',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_1',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/Const_1',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_2/dim',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_2',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/Const_2',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/concat_1/axis',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/concat_1',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/zeros_1/Const',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/zeros_1',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_3/dim',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_3',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/Const_3',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/Shape_1',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/stack',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/Equal',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/Const',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/All',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/Assert/Const',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/Assert/Const_1',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/Assert/Assert/data_0',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/Assert/Assert/data_2',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/Assert/Assert',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/CheckSeqLen',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/Shape_2',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/strided_slice_1/stack',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/strided_slice_1/stack_1',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/strided_slice_1/stack_2',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/strided_slice_1',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/Shape_3',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/strided_slice_2/stack',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/strided_slice_2/stack_1',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/strided_slice_2/stack_2',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/strided_slice_2',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/ExpandDims/dim',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/ExpandDims',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/Const_1',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/concat_1/axis',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/concat_1',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/zeros/Const',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/zeros',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/Const_2',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/Min',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/Const_3',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/Max',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/time',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/TensorArray',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/TensorArray_1',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/TensorArrayUnstack/Shape',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice/stack',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice/stack_1',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice/stack_2',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/TensorArrayUnstack/range/start',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/TensorArrayUnstack/range/delta',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/TensorArrayUnstack/range',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/Maximum/x',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/Maximum',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/Minimum',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/iteration_counter',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Enter',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Enter_1',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Enter_2',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Enter_3',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Enter_4',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Merge',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Merge_1',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Merge_2',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Merge_3',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Merge_4',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Less/Enter',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Less',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Less_1/Enter',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Less_1',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/LogicalAnd',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/LoopCond',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Switch',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Switch_1',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Switch_2',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Switch_3',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Switch_4',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Identity',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Identity_1',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Identity_2',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Identity_3',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Identity_4',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/add/y',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/add',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/TensorArrayReadV3',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/GreaterEqual/Enter',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/GreaterEqual',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/sub/x',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/sub/Enter',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/sub',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/dropout/Shape',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/dropout/random_uniform/min',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/dropout/random_uniform/max',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/dropout/random_uniform/RandomUniform',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/dropout/random_uniform/sub',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/dropout/random_uniform/mul',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/dropout/random_uniform',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/dropout/sub/x',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/dropout/sub',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/dropout/truediv/x',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/dropout/truediv',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/dropout/GreaterEqual',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/dropout/mul',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/dropout/Cast',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/dropout/mul_1',\n",
              " 'codificador_1/bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/shape',\n",
              " 'codificador_1/bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/min',\n",
              " 'codificador_1/bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/max',\n",
              " 'codificador_1/bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/RandomUniform',\n",
              " 'codificador_1/bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/sub',\n",
              " 'codificador_1/bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/mul',\n",
              " 'codificador_1/bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform',\n",
              " 'codificador_1/bidirectional_rnn/fw/lstm_cell/kernel',\n",
              " 'codificador_1/bidirectional_rnn/fw/lstm_cell/kernel/Assign',\n",
              " 'codificador_1/bidirectional_rnn/fw/lstm_cell/kernel/read',\n",
              " 'codificador_1/bidirectional_rnn/fw/lstm_cell/bias/Initializer/zeros/shape_as_tensor',\n",
              " 'codificador_1/bidirectional_rnn/fw/lstm_cell/bias/Initializer/zeros/Const',\n",
              " 'codificador_1/bidirectional_rnn/fw/lstm_cell/bias/Initializer/zeros',\n",
              " 'codificador_1/bidirectional_rnn/fw/lstm_cell/bias',\n",
              " 'codificador_1/bidirectional_rnn/fw/lstm_cell/bias/Assign',\n",
              " 'codificador_1/bidirectional_rnn/fw/lstm_cell/bias/read',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/lstm_cell/concat/axis',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/lstm_cell/concat',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/lstm_cell/MatMul/Enter',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/lstm_cell/MatMul',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/lstm_cell/BiasAdd/Enter',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/lstm_cell/BiasAdd',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/lstm_cell/Const',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/lstm_cell/split/split_dim',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/lstm_cell/split',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/lstm_cell/add/y',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/lstm_cell/add',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/lstm_cell/Sigmoid',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/lstm_cell/mul',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/lstm_cell/Sigmoid_1',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/lstm_cell/Tanh',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/lstm_cell/mul_1',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/lstm_cell/add_1',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/lstm_cell/Sigmoid_2',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/lstm_cell/Tanh_1',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/lstm_cell/mul_2',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Select/Enter',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Select',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Select_1',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Select_2',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3/Enter',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/add_1/y',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/add_1',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/NextIteration',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/NextIteration_1',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/NextIteration_2',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/NextIteration_3',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/NextIteration_4',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Exit',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Exit_1',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Exit_2',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Exit_3',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Exit_4',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/TensorArrayStack/TensorArraySizeV3',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/TensorArrayStack/range/start',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/TensorArrayStack/range/delta',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/TensorArrayStack/range',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/TensorArrayStack/TensorArrayGatherV3',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/Const_4',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/Rank_1',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/range_1/start',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/range_1/delta',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/range_1',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/concat_2/values_0',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/concat_2/axis',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/concat_2',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/transpose_1',\n",
              " 'codificador_1/bidirectional_rnn/bw/ReverseSequence',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/Rank',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/range/start',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/range/delta',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/range',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/concat/values_0',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/concat/axis',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/concat',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/transpose',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/sequence_length',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/Shape',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/strided_slice/stack',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/strided_slice/stack_1',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/strided_slice/stack_2',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/strided_slice',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims/dim',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/Const',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/concat/axis',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/concat',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/zeros/Const',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/zeros',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_1/dim',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_1',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/Const_1',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_2/dim',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_2',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/Const_2',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/concat_1/axis',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/concat_1',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/zeros_1/Const',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/zeros_1',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_3/dim',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_3',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/Const_3',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/Shape_1',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/stack',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/Equal',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/Const',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/All',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/Assert/Const',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/Assert/Const_1',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/Assert/Assert/data_0',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/Assert/Assert/data_2',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/Assert/Assert',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/CheckSeqLen',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/Shape_2',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/strided_slice_1/stack',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/strided_slice_1/stack_1',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/strided_slice_1/stack_2',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/strided_slice_1',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/Shape_3',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/strided_slice_2/stack',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/strided_slice_2/stack_1',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/strided_slice_2/stack_2',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/strided_slice_2',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/ExpandDims/dim',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/ExpandDims',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/Const_1',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/concat_1/axis',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/concat_1',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/zeros/Const',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/zeros',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/Const_2',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/Min',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/Const_3',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/Max',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/time',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/TensorArray',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/TensorArray_1',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/TensorArrayUnstack/Shape',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice/stack',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice/stack_1',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice/stack_2',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/TensorArrayUnstack/range/start',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/TensorArrayUnstack/range/delta',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/TensorArrayUnstack/range',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/Maximum/x',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/Maximum',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/Minimum',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/iteration_counter',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/Enter',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/Enter_1',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/Enter_2',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/Enter_3',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/Enter_4',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/Merge',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/Merge_1',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/Merge_2',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/Merge_3',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/Merge_4',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/Less/Enter',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/Less',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/Less_1/Enter',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/Less_1',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/LogicalAnd',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/LoopCond',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/Switch',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/Switch_1',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/Switch_2',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/Switch_3',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/Switch_4',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/Identity',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/Identity_1',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/Identity_2',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/Identity_3',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/Identity_4',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/add/y',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/add',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/TensorArrayReadV3',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/GreaterEqual/Enter',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/GreaterEqual',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/sub/x',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/sub/Enter',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/sub',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/dropout/Shape',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/dropout/random_uniform/min',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/dropout/random_uniform/max',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/dropout/random_uniform/RandomUniform',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/dropout/random_uniform/sub',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/dropout/random_uniform/mul',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/dropout/random_uniform',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/dropout/sub/x',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/dropout/sub',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/dropout/truediv/x',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/dropout/truediv',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/dropout/GreaterEqual',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/dropout/mul',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/dropout/Cast',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/dropout/mul_1',\n",
              " 'codificador_1/bidirectional_rnn/bw/lstm_cell/kernel/Initializer/random_uniform/shape',\n",
              " 'codificador_1/bidirectional_rnn/bw/lstm_cell/kernel/Initializer/random_uniform/min',\n",
              " 'codificador_1/bidirectional_rnn/bw/lstm_cell/kernel/Initializer/random_uniform/max',\n",
              " 'codificador_1/bidirectional_rnn/bw/lstm_cell/kernel/Initializer/random_uniform/RandomUniform',\n",
              " 'codificador_1/bidirectional_rnn/bw/lstm_cell/kernel/Initializer/random_uniform/sub',\n",
              " 'codificador_1/bidirectional_rnn/bw/lstm_cell/kernel/Initializer/random_uniform/mul',\n",
              " 'codificador_1/bidirectional_rnn/bw/lstm_cell/kernel/Initializer/random_uniform',\n",
              " 'codificador_1/bidirectional_rnn/bw/lstm_cell/kernel',\n",
              " 'codificador_1/bidirectional_rnn/bw/lstm_cell/kernel/Assign',\n",
              " 'codificador_1/bidirectional_rnn/bw/lstm_cell/kernel/read',\n",
              " 'codificador_1/bidirectional_rnn/bw/lstm_cell/bias/Initializer/zeros/shape_as_tensor',\n",
              " 'codificador_1/bidirectional_rnn/bw/lstm_cell/bias/Initializer/zeros/Const',\n",
              " 'codificador_1/bidirectional_rnn/bw/lstm_cell/bias/Initializer/zeros',\n",
              " 'codificador_1/bidirectional_rnn/bw/lstm_cell/bias',\n",
              " 'codificador_1/bidirectional_rnn/bw/lstm_cell/bias/Assign',\n",
              " 'codificador_1/bidirectional_rnn/bw/lstm_cell/bias/read',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/lstm_cell/concat/axis',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/lstm_cell/concat',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/lstm_cell/MatMul/Enter',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/lstm_cell/MatMul',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/lstm_cell/BiasAdd/Enter',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/lstm_cell/BiasAdd',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/lstm_cell/Const',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/lstm_cell/split/split_dim',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/lstm_cell/split',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/lstm_cell/add/y',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/lstm_cell/add',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/lstm_cell/Sigmoid',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/lstm_cell/mul',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/lstm_cell/Sigmoid_1',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/lstm_cell/Tanh',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/lstm_cell/mul_1',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/lstm_cell/add_1',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/lstm_cell/Sigmoid_2',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/lstm_cell/Tanh_1',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/lstm_cell/mul_2',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/Select/Enter',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/Select',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/Select_1',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/Select_2',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3/Enter',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/add_1/y',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/add_1',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/NextIteration',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/NextIteration_1',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/NextIteration_2',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/NextIteration_3',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/NextIteration_4',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/Exit',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/Exit_1',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/Exit_2',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/Exit_3',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/while/Exit_4',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/TensorArrayStack/TensorArraySizeV3',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/TensorArrayStack/range/start',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/TensorArrayStack/range/delta',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/TensorArrayStack/range',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/TensorArrayStack/TensorArrayGatherV3',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/Const_4',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/Rank_1',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/range_1/start',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/range_1/delta',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/range_1',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/concat_2/values_0',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/concat_2/axis',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/concat_2',\n",
              " 'codificador_1/bidirectional_rnn/bw/bw/transpose_1',\n",
              " 'codificador_1/ReverseSequence',\n",
              " 'concat/axis',\n",
              " 'concat',\n",
              " 'StridedSlice/begin',\n",
              " 'StridedSlice/end',\n",
              " 'StridedSlice/strides',\n",
              " 'StridedSlice',\n",
              " 'Fill/dims',\n",
              " 'Fill/value',\n",
              " 'Fill',\n",
              " 'concat_1/axis',\n",
              " 'concat_1',\n",
              " 'embedding_lookup_1/params_0',\n",
              " 'embedding_lookup_1/axis',\n",
              " 'embedding_lookup_1',\n",
              " 'embedding_lookup_1/Identity',\n",
              " 'decodificador_0/DropoutWrapperInit/Const',\n",
              " 'decodificador_0/DropoutWrapperInit/Const_1',\n",
              " 'decodificador_1/DropoutWrapperInit/Const',\n",
              " 'decodificador_1/DropoutWrapperInit/Const_1',\n",
              " 'BahdanauAttention/Shape',\n",
              " 'BahdanauAttention/strided_slice/stack',\n",
              " 'BahdanauAttention/strided_slice/stack_1',\n",
              " 'BahdanauAttention/strided_slice/stack_2',\n",
              " 'BahdanauAttention/strided_slice',\n",
              " 'BahdanauAttention/SequenceMask/Const',\n",
              " 'BahdanauAttention/SequenceMask/Const_1',\n",
              " 'BahdanauAttention/SequenceMask/Range',\n",
              " 'BahdanauAttention/SequenceMask/ExpandDims/dim',\n",
              " 'BahdanauAttention/SequenceMask/ExpandDims',\n",
              " 'BahdanauAttention/SequenceMask/Cast',\n",
              " 'BahdanauAttention/SequenceMask/Less',\n",
              " 'BahdanauAttention/SequenceMask/Cast_1',\n",
              " 'BahdanauAttention/ones/shape_as_tensor',\n",
              " 'BahdanauAttention/ones/Const',\n",
              " 'BahdanauAttention/ones',\n",
              " 'BahdanauAttention/Shape_1',\n",
              " 'BahdanauAttention/concat/axis',\n",
              " 'BahdanauAttention/concat',\n",
              " 'BahdanauAttention/Reshape',\n",
              " 'BahdanauAttention/mul',\n",
              " 'memory_layer/kernel/Initializer/random_uniform/shape',\n",
              " 'memory_layer/kernel/Initializer/random_uniform/min',\n",
              " 'memory_layer/kernel/Initializer/random_uniform/max',\n",
              " 'memory_layer/kernel/Initializer/random_uniform/RandomUniform',\n",
              " 'memory_layer/kernel/Initializer/random_uniform/sub',\n",
              " 'memory_layer/kernel/Initializer/random_uniform/mul',\n",
              " 'memory_layer/kernel/Initializer/random_uniform',\n",
              " 'memory_layer/kernel',\n",
              " 'memory_layer/kernel/Assign',\n",
              " 'memory_layer/kernel/read',\n",
              " 'BahdanauAttention/memory_layer/Tensordot/axes',\n",
              " 'BahdanauAttention/memory_layer/Tensordot/free',\n",
              " 'BahdanauAttention/memory_layer/Tensordot/Shape',\n",
              " 'BahdanauAttention/memory_layer/Tensordot/GatherV2/axis',\n",
              " 'BahdanauAttention/memory_layer/Tensordot/GatherV2',\n",
              " 'BahdanauAttention/memory_layer/Tensordot/GatherV2_1/axis',\n",
              " 'BahdanauAttention/memory_layer/Tensordot/GatherV2_1',\n",
              " 'BahdanauAttention/memory_layer/Tensordot/Const',\n",
              " 'BahdanauAttention/memory_layer/Tensordot/Prod',\n",
              " 'BahdanauAttention/memory_layer/Tensordot/Const_1',\n",
              " 'BahdanauAttention/memory_layer/Tensordot/Prod_1',\n",
              " 'BahdanauAttention/memory_layer/Tensordot/concat/axis',\n",
              " 'BahdanauAttention/memory_layer/Tensordot/concat',\n",
              " 'BahdanauAttention/memory_layer/Tensordot/stack',\n",
              " 'BahdanauAttention/memory_layer/Tensordot/transpose',\n",
              " 'BahdanauAttention/memory_layer/Tensordot/Reshape',\n",
              " 'BahdanauAttention/memory_layer/Tensordot/transpose_1/perm',\n",
              " 'BahdanauAttention/memory_layer/Tensordot/transpose_1',\n",
              " 'BahdanauAttention/memory_layer/Tensordot/Reshape_1/shape',\n",
              " 'BahdanauAttention/memory_layer/Tensordot/Reshape_1',\n",
              " 'BahdanauAttention/memory_layer/Tensordot/MatMul',\n",
              " 'BahdanauAttention/memory_layer/Tensordot/Const_2',\n",
              " 'BahdanauAttention/memory_layer/Tensordot/concat_1/axis',\n",
              " 'BahdanauAttention/memory_layer/Tensordot/concat_1',\n",
              " 'BahdanauAttention/memory_layer/Tensordot',\n",
              " 'BahdanauAttention/Shape_2',\n",
              " 'BahdanauAttention/strided_slice_1/stack',\n",
              " 'BahdanauAttention/strided_slice_1/stack_1',\n",
              " 'BahdanauAttention/strided_slice_1/stack_2',\n",
              " 'BahdanauAttention/strided_slice_1',\n",
              " 'BahdanauAttention/Shape_3',\n",
              " 'BahdanauAttention/strided_slice_2/stack',\n",
              " 'BahdanauAttention/strided_slice_2/stack_1',\n",
              " 'BahdanauAttention/strided_slice_2/stack_2',\n",
              " 'BahdanauAttention/strided_slice_2',\n",
              " 'AttentionWrapperZeroState/DropoutWrapperZeroState/LSTMCellZeroState/Const',\n",
              " 'AttentionWrapperZeroState/DropoutWrapperZeroState/LSTMCellZeroState/Const_1',\n",
              " 'AttentionWrapperZeroState/DropoutWrapperZeroState/LSTMCellZeroState/concat/axis',\n",
              " 'AttentionWrapperZeroState/DropoutWrapperZeroState/LSTMCellZeroState/concat',\n",
              " 'AttentionWrapperZeroState/DropoutWrapperZeroState/LSTMCellZeroState/zeros/Const',\n",
              " 'AttentionWrapperZeroState/DropoutWrapperZeroState/LSTMCellZeroState/zeros',\n",
              " 'AttentionWrapperZeroState/DropoutWrapperZeroState/LSTMCellZeroState/Const_2',\n",
              " 'AttentionWrapperZeroState/DropoutWrapperZeroState/LSTMCellZeroState/Const_3',\n",
              " 'AttentionWrapperZeroState/DropoutWrapperZeroState/LSTMCellZeroState/Const_4',\n",
              " 'AttentionWrapperZeroState/DropoutWrapperZeroState/LSTMCellZeroState/Const_5',\n",
              " 'AttentionWrapperZeroState/DropoutWrapperZeroState/LSTMCellZeroState/concat_1/axis',\n",
              " 'AttentionWrapperZeroState/DropoutWrapperZeroState/LSTMCellZeroState/concat_1',\n",
              " 'AttentionWrapperZeroState/DropoutWrapperZeroState/LSTMCellZeroState/zeros_1/Const',\n",
              " 'AttentionWrapperZeroState/DropoutWrapperZeroState/LSTMCellZeroState/zeros_1',\n",
              " 'AttentionWrapperZeroState/DropoutWrapperZeroState/LSTMCellZeroState/Const_6',\n",
              " 'AttentionWrapperZeroState/DropoutWrapperZeroState/LSTMCellZeroState/Const_7',\n",
              " 'AttentionWrapperZeroState/assert_equal/x',\n",
              " 'AttentionWrapperZeroState/assert_equal/Equal',\n",
              " 'AttentionWrapperZeroState/assert_equal/Const',\n",
              " 'AttentionWrapperZeroState/assert_equal/All',\n",
              " 'AttentionWrapperZeroState/assert_equal/Assert/Const',\n",
              " 'AttentionWrapperZeroState/assert_equal/Assert/Const_1',\n",
              " 'AttentionWrapperZeroState/assert_equal/Assert/Const_2',\n",
              " 'AttentionWrapperZeroState/assert_equal/Assert/Const_3',\n",
              " 'AttentionWrapperZeroState/assert_equal/Assert/Assert/data_0',\n",
              " 'AttentionWrapperZeroState/assert_equal/Assert/Assert/data_1',\n",
              " 'AttentionWrapperZeroState/assert_equal/Assert/Assert/data_2',\n",
              " 'AttentionWrapperZeroState/assert_equal/Assert/Assert/data_4',\n",
              " 'AttentionWrapperZeroState/assert_equal/Assert/Assert',\n",
              " 'AttentionWrapperZeroState/checked_cell_state',\n",
              " 'AttentionWrapperZeroState/checked_cell_state_1',\n",
              " 'AttentionWrapperZeroState/Const',\n",
              " 'AttentionWrapperZeroState/ExpandDims/dim',\n",
              " 'AttentionWrapperZeroState/ExpandDims',\n",
              " 'AttentionWrapperZeroState/concat/axis',\n",
              " 'AttentionWrapperZeroState/concat',\n",
              " 'AttentionWrapperZeroState/zeros/Const',\n",
              " 'AttentionWrapperZeroState/zeros',\n",
              " 'AttentionWrapperZeroState/Const_1',\n",
              " 'AttentionWrapperZeroState/ExpandDims_1/dim',\n",
              " 'AttentionWrapperZeroState/ExpandDims_1',\n",
              " 'AttentionWrapperZeroState/zeros_1',\n",
              " 'AttentionWrapperZeroState/Const_2',\n",
              " 'AttentionWrapperZeroState/Const_3',\n",
              " 'AttentionWrapperZeroState/concat_1/axis',\n",
              " 'AttentionWrapperZeroState/concat_1',\n",
              " 'AttentionWrapperZeroState/zeros_2/Const',\n",
              " 'AttentionWrapperZeroState/zeros_2',\n",
              " 'AttentionWrapperZeroState/Const_4',\n",
              " 'AttentionWrapperZeroState/Const_5',\n",
              " 'AttentionWrapperZeroState/Const_6',\n",
              " 'AttentionWrapperZeroState/ExpandDims_2/dim',\n",
              " 'AttentionWrapperZeroState/ExpandDims_2',\n",
              " 'AttentionWrapperZeroState/concat_2/axis',\n",
              " 'AttentionWrapperZeroState/concat_2',\n",
              " 'AttentionWrapperZeroState/zeros_3/Const',\n",
              " 'AttentionWrapperZeroState/zeros_3',\n",
              " 'AttentionWrapperZeroState/Const_7',\n",
              " 'AttentionWrapperZeroState/ExpandDims_3/dim',\n",
              " 'AttentionWrapperZeroState/ExpandDims_3',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Exit_3/assert_shape/actual',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Exit_3/assert_shape/is_shape/Size/Const',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Exit_3/assert_shape/is_shape/Size',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Exit_3/assert_shape/is_shape/is_rank/actual',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Exit_3/assert_shape/is_shape/is_rank',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Exit_3/assert_shape/is_shape/shape_tensor_equal/Equal/x',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Exit_3/assert_shape/is_shape/shape_tensor_equal/Equal/y',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Exit_3/assert_shape/is_shape/shape_tensor_equal/Equal',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Exit_3/assert_shape/is_shape/shape_tensor_equal/equal_1/x',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Exit_3/assert_shape/is_shape/shape_tensor_equal/equal_1',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Exit_3/assert_shape/is_shape/shape_tensor_equal/exclude_partial_shape',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Exit_3/assert_shape/is_shape/shape_tensor_equal/Const',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Exit_3/assert_shape/is_shape/shape_tensor_equal',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Exit_3/assert_shape/is_shape',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Exit_3/assert_shape/Const',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Exit_3/assert_shape/Const_1',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Exit_3/assert_shape/Assert/data_0',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Exit_3/assert_shape/Assert/data_1',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Exit_3/assert_shape/Assert',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Exit_3/Identity',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Exit_4/assert_shape/actual',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Exit_4/assert_shape/is_shape/Size/Const',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Exit_4/assert_shape/is_shape/Size',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Exit_4/assert_shape/is_shape/is_rank/actual',\n",
              " 'codificador_1/bidirectional_rnn/fw/fw/while/Exit_4/assert_shape/is_shape/is_rank',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17kiqMedBt_B",
        "colab_type": "text"
      },
      "source": [
        "# Gerando sumários utilizando o modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZfCzxl1KgPR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "def limpar_texto(texto, remover_stopwords=False):\n",
        "    \n",
        "    # Converte o texto para lower case\n",
        "    texto = texto.lower()\n",
        "    \n",
        "    # Remove caracteres indesejados\n",
        "    texto = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', texto, flags=re.MULTILINE)\n",
        "    texto = re.sub(r'\\<a href', ' ', texto)\n",
        "    texto = re.sub(r'&amp;', '', texto) \n",
        "    texto = re.sub(r'[_\"\\%()|+&=*%!?:#$@\\[\\]/]', ' ', texto)\n",
        "    texto = re.sub(r'<br />', ' ', texto)\n",
        "    texto = re.sub(r'\\'', ' ', texto)\n",
        "    \n",
        "    # Opcionalmente, remove stop words\n",
        "    if remover_stopwords:\n",
        "        tokens = [t for t in normalizer.tokenize_words(texto)\n",
        "                    if t not in STOPWORDS]\n",
        "        texto = detokenizer.detokenize(tokens, return_str=True)\n",
        "        \n",
        "    return texto"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvRPGfo7Gxl2",
        "colab_type": "text"
      },
      "source": [
        "Carregando textos do dataset para serem usados nos testes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sywNXDvGwxH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "titulos, textos = carregar_dados_pickle(\"drive/My Drive/text_sumarizer/data/titulos_e_textos.pickle\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rj-bHsOudH6U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def usr_texto2seq(texto):\n",
        "    '''Prepara o texto para o modelo'''\n",
        "    \n",
        "    texto = limpar_texto(texto)\n",
        "    return [token2int.get(token, token2int['<UNK>']) \n",
        "            for token in texto.split()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8QXQA2lB0k8",
        "colab_type": "code",
        "outputId": "847c94b0-9a07-4cbf-c128-d902a965555f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "indice_aleatorio = np.random.randint(0,len(int_textos_ord))\n",
        "texto_entrada = textos[indice_aleatorio]\n",
        "int_texto = usr_texto2seq(textos[indice_aleatorio])\n",
        "\n",
        "checkpoint = \"drive/My Drive/text_sumarizer/models/sum/best_model.ckpt\"\n",
        "\n",
        "grafo_carregado = tf.Graph()\n",
        "with tf.Session(graph=grafo_carregado) as sess:\n",
        "    # Carrega o modelo salvo\n",
        "    loader = tf.train.import_meta_graph(checkpoint + '.meta')\n",
        "    loader.restore(sess, checkpoint)\n",
        "\n",
        "    dados_entrada = grafo_carregado.get_tensor_by_name('entrada:0')\n",
        "    logits = grafo_carregado.get_tensor_by_name('predicoes:0')\n",
        "    tam_texto = grafo_carregado.get_tensor_by_name('tam_texto:0')\n",
        "    tam_sumario = grafo_carregado.get_tensor_by_name('tam_sumario:0')\n",
        "    keep_prob = grafo_carregado.get_tensor_by_name('keep_prob:0')\n",
        "    \n",
        "    # Multiplica por batch_size para ficar igual aos parâmetros de entrada do modelo\n",
        "    resposta_logits = sess.run(logits, {dados_entrada: [int_texto]*batch_size, \n",
        "                                      tam_sumario: [np.random.randint(5,8)], \n",
        "                                      tam_texto: [len(int_texto)]*batch_size,\n",
        "                                      keep_prob: 1.0})[0] \n",
        "\n",
        "# Remove o pad\n",
        "pad = token2int[\"<PAD>\"] \n",
        "\n",
        "print(\"Texto original:\", textos[indice_aleatorio])\n",
        "print(\"Sumário original:\", titulos[indice_aleatorio])\n",
        "\n",
        "print(\"\\nTexto\")\n",
        "print(f\"  Ids dos tokens:    {[i for i in int_texto]}\")\n",
        "print(f\"  Tokens de entrada: {[int2token[i] for i in int_texto]}\")\n",
        "\n",
        "print(\"\\nSumario\")\n",
        "print(f\"  Ids dos tokens:    {[i for i in resposta_logits if i != pad]}\")\n",
        "print(f\"  Resposta textual:  {[int2token[i] for i in resposta_logits if i != pad]}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0624 20:34:50.006259 140348186097536 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Texto original: chama beta, chama melo. tome gêmeos, tamanha semelhança física brinque jogo sete erros foto desta página, demi moore. musa irmão, diz pernambucana roberta britto, 49 anos, dois menos romero. pinta. várias telas. melo tira beta sério vezes. raiva porque é família, famílias brigam, diz folha sentada poltrona romero britto, venda r 7.000 galeria roberta britto, rua oscar freire, paulo. lá vende obras irmão artistas trabalham material orgânico pop art. livro ainda título, caçula nove irmãos 49 69 anos narra história clã britto –e não poupa passagens mais cinzentas obra familiar famoso. 200 páginas escritas, inseriu críticas suposto descaso romero câncer matou mãe 2012, 89 anos. não. nenhum irmão trouxe fralda sequer pra mãe, reclama josé antônio, romulo, rosemiro, robson, roberval, risoleta romero. nono irmão, austriclinio, morreu. meio porta-voz, artista responde é muito triste pessoas sugerem contrário, sido sempre generoso família,, enquanto puder, continuarei sê-lo. é família romero britto puxar, diz roberta. mãe mulher frente tempo. verdade, veia artística. manicure, arte não valorizada. fazia crochê, boneca pano, cocada. empregada doméstica, criava porcos ficaram bem gordos. menino, poder comprar materiais adequados, romero usava esmaltes dona maria pintar, base não, vai, lembra irmã. improvisava telas paredes caixas papelão. maria lourdes marques santos rosemiro silva brito filha bastarda latifundiário. marido outras famílias não tão presente, roberta diz pai. 2009, médicos diagnosticaram câncer peritônio. é pegou hebe camargo, deixa estômago inflado, parece pessoa comeu demais. conta hospital santa catarina, avenida paulista, salgada –sem especificar valor, sinaliza algo torno r 100 mil. não ia colocar mãe sus. dívida, diz, ainda existe, daí cobrança irmão famoso. impasse. tempo cuidava matriarca, descobriu câncer -removeu mama esquerda 33 linfonodos. não romero não ligue. após operar seios, exemplo, roberta acordou, lá, champanhe duas taças. pra celebrar. problema, diz, é trabalha demais. visitava mãe irmã doentes brasil, aproveitava fazia agenda profissional. risco morte corria beta, melo não vida. romero é muito generoso, dá dinheiro pra caridade. não pode esquecer nunca real família. vez florianópolis vi cauã reymond mãe. quanto carinho... é faz-tudo apesar desavenças pontuais, família é unida, segundo roberta. conta irmão levou 1989 morar miami. aprendeu inglês canções bee gees ficou duas décadas. virou faz-tudo galeria romero britto faxina ajudar pintar várias demãos tinta quadros. modelo dia 1990, desfilou maiô cavado absolut vodca fez campanha marca. gostou eua. brasil pessoas mais aculturadas. lá gostam arte, colecionam brindes mcdonald s, cartas beisebol. voltou. roberta, descobriu gay 27 anos, mora companheira maravilhosa vai bicicleta galeria oscar freire. todos pouco gay, animais, opina, querer falar sexualidade irmão casado filho 25 anos, brendan. não diz respeito. diz respeito, sim, é desprezo crítica local reserva romero. cita tom jobim brasil, fazer sucesso é ofensa pessoal nelson rodrigues toda unanimidade é burra. biografia andamento, escreveu falo arte ser usufruída coca-cola é porque vejo romero consegue ser acessível todos. crê vezes falta critério. bom ar aromatizante ilustrações romero, exemplo. logo é muito maior imagens. desvalorizou ideia.\n",
            "Sumário original: irmã de romero britto escreve livro e acusa artista de desleixo com a mãe\n",
            "\n",
            "Texto\n",
            "  Ids dos tokens:    [1949, 269656, 1949, 269656, 10429, 269656, 7931, 9746, 1647, 72208, 230, 436, 1902, 1531, 135, 269656, 44179, 269656, 11895, 269656, 16, 13933, 10611, 269656, 3377, 269656, 27, 43, 269656, 269656, 817, 269656, 2600, 4444, 33990, 2878, 56756, 6264, 48, 2, 269656, 961, 269656, 16, 60, 9825, 15951, 3397, 269656, 525, 6, 9595, 3131, 10611, 269656, 330, 1637, 269656, 22953, 273, 4000, 341, 1659, 1181, 2952, 1326, 11559, 2931, 269656, 316, 12, 269656, 10723, 896, 1921, 3377, 5726, 8, 7098, 142, 16639, 10367, 1335, 3, 19847, 2972, 4, 48836, 412, 2599, 269656, 1010, 2363, 269656, 32977, 841, 3041, 11842, 3397, 1458, 2650, 514, 269656, 7006, 13300, 28734, 428, 1659, 3134, 28732, 2665, 770, 269656, 5369, 238, 269656, 269656, 269656, 269656, 269656, 72395, 269656, 9501, 269656, 269656, 157725, 87, 269656, 965, 2541, 2, 23, 3042, 26, 5719, 269656, 109, 113, 12397, 269656, 137, 269656, 31234, 269656, 2, 218, 3397, 10367, 269656, 16, 269656, 514, 234, 227, 30994, 269656, 17047, 136869, 269656, 647, 3, 269656, 1476, 269656, 16701, 269656, 269656, 8499, 269656, 20378, 15691, 1172, 75, 269656, 269656, 184, 1070, 2685, 269656, 3397, 5701, 39009, 1992, 620, 269656, 259, 269656, 269656, 1540, 269656, 93800, 5163, 4293, 4579, 269656, 620, 18059, 3405, 297, 158600, 429, 8440, 1031, 90663, 269656, 1508, 110, 961, 3, 226, 269656, 10611, 16, 72639, 269656, 1086, 60549, 1458, 269656, 2, 3832, 28379, 269656, 746, 11260, 269656, 402, 271, 16745, 58597, 100, 741, 1004, 269656, 937, 269656, 20904, 13230, 17597, 269656, 10211, 331, 1085, 6, 546, 39676, 3, 2072, 1018, 514, 269656, 269656, 269656, 12, 269656, 2336, 1856, 1659, 269656, 269656, 55, 16312, 269656, 3903, 1458, 269656, 12549, 849, 2176, 269656, 3, 3397, 3, 269656, 28, 4040, 269656, 269656, 10611, 269656, 269656, 14180, 73, 269656, 770, 269656, 269656, 269656, 2, 1402, 58597, 19680, 514, 2892, 8521, 269656, 32020, 1476, 1078, 68722, 283, 347, 11353, 269656, 2600, 3, 28367, 3397, 2, 23, 269656, 339, 129, 770, 269656, 3, 24, 5340, 208, 474, 39773, 59, 5640, 1944, 27670, 36541, 72993, 138, 269656, 2, 58003, 206, 21632, 269656, 218, 2, 269656, 11, 269656, 100, 1659, 661, 6175, 4577, 269656, 6209, 898, 2722, 37918, 85919, 233, 73, 63583, 1390, 58003, 3131, 3397, 10367, 17727, 790, 11037, 817, 114724, 6853, 269656, 584, 29, 269656, 22855, 38285, 50441, 88689, 18760, 125, 195, 82907, 7688, 43500, 14, 26, 4, 269656, 273, 5874, 269656, 61493, 25100, 9754, 269656, 3871, 269656, 269656, 269656, 3903, 3358, 675, 269656, 2412, 10484, 10398, 30, 3976, 3131, 1637, 269656, 49, 140, 269656, 269656, 269656, 2550, 437, 8919, 1659, 5282, 267, 311, 269656, 269656, 3, 16, 82916, 16, 269656, 269656, 2, 11245, 1309, 173, 2059, 269656, 2809, 1229, 7028, 269656, 34, 659, 2, 12422, 822, 2319, 1915, 353, 6199, 2, 269656, 4425, 269656, 989, 6145, 647, 5, 93904, 9287, 2, 48, 2561, 3397, 1534, 5, 7589, 47638, 12116, 166, 276, 269656, 252, 1096, 155155, 8753, 269656, 34395, 534, 2, 23, 35, 269656, 26692, 75357]\n",
            "  Tokens de entrada: ['chama', '<UNK>', 'chama', '<UNK>', 'tome', '<UNK>', 'tamanha', 'semelhança', 'física', 'brinque', 'jogo', 'sete', 'erros', 'foto', 'desta', '<UNK>', 'demi', '<UNK>', 'musa', '<UNK>', 'diz', 'pernambucana', 'roberta', '<UNK>', '49', '<UNK>', 'dois', 'menos', '<UNK>', '<UNK>', 'várias', '<UNK>', 'melo', 'tira', 'beta', 'sério', 'vezes.', 'raiva', 'porque', 'é', '<UNK>', 'famílias', '<UNK>', 'diz', 'folha', 'sentada', 'poltrona', 'romero', '<UNK>', 'venda', 'r', '7.000', 'galeria', 'roberta', '<UNK>', 'rua', 'oscar', '<UNK>', 'paulo.', 'lá', 'vende', 'obras', 'irmão', 'artistas', 'trabalham', 'material', 'orgânico', 'pop', '<UNK>', 'livro', 'ainda', '<UNK>', 'caçula', 'nove', 'irmãos', '49', '69', 'anos', 'narra', 'história', 'clã', 'britto', '–e', 'não', 'poupa', 'passagens', 'mais', 'cinzentas', 'obra', 'familiar', '<UNK>', '200', 'páginas', '<UNK>', 'inseriu', 'críticas', 'suposto', 'descaso', 'romero', 'câncer', 'matou', 'mãe', '<UNK>', '89', 'anos.', 'não.', 'nenhum', 'irmão', 'trouxe', 'fralda', 'sequer', 'pra', '<UNK>', 'reclama', 'josé', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', 'risoleta', '<UNK>', 'nono', '<UNK>', '<UNK>', 'morreu.', 'meio', '<UNK>', 'artista', 'responde', 'é', 'muito', 'triste', 'pessoas', 'sugerem', '<UNK>', 'sido', 'sempre', 'generoso', '<UNK>', 'enquanto', '<UNK>', 'continuarei', '<UNK>', 'é', 'família', 'romero', 'britto', '<UNK>', 'diz', '<UNK>', 'mãe', 'mulher', 'frente', 'tempo.', '<UNK>', 'veia', 'artística.', '<UNK>', 'arte', 'não', '<UNK>', 'fazia', '<UNK>', 'boneca', '<UNK>', '<UNK>', 'empregada', '<UNK>', 'criava', 'porcos', 'ficaram', 'bem', '<UNK>', '<UNK>', 'poder', 'comprar', 'materiais', '<UNK>', 'romero', 'usava', 'esmaltes', 'dona', 'maria', '<UNK>', 'base', '<UNK>', '<UNK>', 'lembra', '<UNK>', 'improvisava', 'telas', 'paredes', 'caixas', '<UNK>', 'maria', 'lourdes', 'marques', 'santos', 'rosemiro', 'silva', 'brito', 'filha', 'bastarda', '<UNK>', 'marido', 'outras', 'famílias', 'não', 'tão', '<UNK>', 'roberta', 'diz', 'pai.', '<UNK>', 'médicos', 'diagnosticaram', 'câncer', '<UNK>', 'é', 'pegou', 'hebe', '<UNK>', 'deixa', 'estômago', '<UNK>', 'parece', 'pessoa', 'comeu', 'demais.', 'conta', 'hospital', 'santa', '<UNK>', 'avenida', '<UNK>', 'salgada', '–sem', 'especificar', '<UNK>', 'sinaliza', 'algo', 'torno', 'r', '100', 'mil.', 'não', 'ia', 'colocar', 'mãe', '<UNK>', '<UNK>', '<UNK>', 'ainda', '<UNK>', 'daí', 'cobrança', 'irmão', '<UNK>', '<UNK>', 'tempo', 'cuidava', '<UNK>', 'descobriu', 'câncer', '<UNK>', 'mama', 'esquerda', '33', '<UNK>', 'não', 'romero', 'não', '<UNK>', 'após', 'operar', '<UNK>', '<UNK>', 'roberta', '<UNK>', '<UNK>', 'champanhe', 'duas', '<UNK>', 'pra', '<UNK>', '<UNK>', '<UNK>', 'é', 'trabalha', 'demais.', 'visitava', 'mãe', 'irmã', 'doentes', '<UNK>', 'aproveitava', 'fazia', 'agenda', 'profissional.', 'risco', 'morte', 'corria', '<UNK>', 'melo', 'não', 'vida.', 'romero', 'é', 'muito', '<UNK>', 'dá', 'dinheiro', 'pra', '<UNK>', 'não', 'pode', 'esquecer', 'nunca', 'real', 'família.', 'vez', 'florianópolis', 'vi', 'cauã', 'reymond', 'mãe.', 'quanto', '<UNK>', 'é', 'faz-tudo', 'apesar', 'desavenças', '<UNK>', 'família', 'é', '<UNK>', 'segundo', '<UNK>', 'conta', 'irmão', 'levou', '1989', 'morar', '<UNK>', 'aprendeu', 'inglês', 'canções', 'bee', 'gees', 'ficou', 'duas', 'décadas.', 'virou', 'faz-tudo', 'galeria', 'romero', 'britto', 'faxina', 'ajudar', 'pintar', 'várias', 'demãos', 'tinta', '<UNK>', 'modelo', 'dia', '<UNK>', 'desfilou', 'maiô', 'cavado', 'absolut', 'vodca', 'fez', 'campanha', 'marca.', 'gostou', 'eua.', 'brasil', 'pessoas', 'mais', '<UNK>', 'lá', 'gostam', '<UNK>', 'colecionam', 'brindes', 'mcdonald', '<UNK>', 'cartas', '<UNK>', '<UNK>', '<UNK>', 'descobriu', 'gay', '27', '<UNK>', 'mora', 'companheira', 'maravilhosa', 'vai', 'bicicleta', 'galeria', 'oscar', '<UNK>', 'todos', 'pouco', '<UNK>', '<UNK>', '<UNK>', 'querer', 'falar', 'sexualidade', 'irmão', 'casado', 'filho', '25', '<UNK>', '<UNK>', 'não', 'diz', 'respeito.', 'diz', '<UNK>', '<UNK>', 'é', 'desprezo', 'crítica', 'local', 'reserva', '<UNK>', 'cita', 'tom', 'jobim', '<UNK>', 'fazer', 'sucesso', 'é', 'ofensa', 'pessoal', 'nelson', 'rodrigues', 'toda', 'unanimidade', 'é', '<UNK>', 'biografia', '<UNK>', 'escreveu', 'falo', 'arte', 'ser', 'usufruída', 'coca-cola', 'é', 'porque', 'vejo', 'romero', 'consegue', 'ser', 'acessível', 'todos.', 'crê', 'vezes', 'falta', '<UNK>', 'bom', 'ar', 'aromatizante', 'ilustrações', '<UNK>', 'exemplo.', 'logo', 'é', 'muito', 'maior', '<UNK>', 'desvalorizou', 'ideia.']\n",
            "\n",
            "Sumario\n",
            "  Ids dos tokens:    [104, 20]\n",
            "  Resposta textual:  ['em', 'de']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}