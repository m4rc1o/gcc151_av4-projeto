# -*- coding: utf-8 -*-
"""sumarizacao.py

Definição da função gerar_sumario que tem como propósito a construção de um
sumário abstrativo curto a partir de um texto qualquer


sumarizacao.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Q4hmLTbDXeYrbOHt3EqqWlo1gp3JLK9V
"""

import re
import pickle
import numpy as np
import tensorflow as tf
from tensorflow.python.layers.core import Dense
from tensorflow.python.ops.rnn_cell_impl import _zero_state_tensors
from nlputils.lexical import normalization as n
import nltk
nltk.download('punkt')
nltk.download('rslp')
nltk.download('stopwords')
normalizer = n.Normalizer()

path_modelo = "models/best_model.ckpt"
path_token2int = "data/token2int_int2token.pickle"

with open(path_token2int, "rb") as infile:
    token2int, int2token = pickle.load(infile)

def __text2int_seq(texto):
    """
    Converte o texto para sua representação inteira,
    de acordo com o modelo
    """
    texto = texto.lower()
    return [token2int.get(token, token2int['<UNK>']) 
            for token in texto.split()]

def gerar_sumario(texto):
    """
    Função que gera um sumário abstrativo de um texto qualquer
    
    params:
        texto: str, o texto a ser sumarizado
    
    return:
        sumaro: str, o sumário referente a 'texto'
    """
    
    batch_size = 64 # TODO: criar uma maneira de carregar essa informação dinamicamente
    
    int_texto = __text2int_seq(texto)
    grafo_carregado = tf.Graph()
    with tf.Session(graph=grafo_carregado) as sess:
        # Carrega o modelo salvo
        loader = tf.train.import_meta_graph(path_modelo + '.meta')
        loader.restore(sess, path_modelo)

        dados_entrada = grafo_carregado.get_tensor_by_name('entrada:0')
        logits = grafo_carregado.get_tensor_by_name('predicoes:0')
        tam_texto = grafo_carregado.get_tensor_by_name('tam_texto:0')
        tam_sumario = grafo_carregado.get_tensor_by_name('tam_sumario:0')
        keep_prob = grafo_carregado.get_tensor_by_name('keep_prob:0')

        # Multiplica por batch_size para ficar igual aos parâmetros de entrada do modelo
        resposta_logits = sess.run(logits, {dados_entrada: [int_texto]*batch_size, 
                                          tam_sumario: [np.random.randint(5,8)], 
                                          tam_texto: [len(int_texto)]*batch_size,
                                          keep_prob: 1.0})[0] 

    # Remove o pad
    pad = token2int["<PAD>"] 

    
    tokens_sumario = [int2token[i] for i in resposta_logits if i != pad]
    sumario = ' '.join(tokens_sumario)
    
    return sumario
